\chapter{Wprowadzenie teoretyczne}
\label{cha:wstepTeoretyczny}

Zrozumienie istoty przedstawionego w tej pracy rozwi±zania u doboru optymalnej trasy narciarza, zarówno pod wzglêdem algorytmicznym jak i architektonicznym, wymaga zaznajomienia siê z istotnymi pojêciami. W tym rozdziale, przedstawimy i opiszemy te pojêcia.

\section{Jazda po zadanym torze w narciarstwie alpejskim}
\label{sec:alpineSkiing}

Sportowa jazda na nartach zjazdowych podzielona jest na kilak dyscyplin. S± to: slalom (SL), slalom gigant (GS), super gigant (GS) oraz zjazd (DH). Elementem wspólnym ka¿dej z nich jest konieczno¶æ pokonania trasy, od startu do mety, w jak najkrótszym czasie i przy prawid³owym ominiêciu ka¿dej z bramek znajduj±cej siê na trasie przejazdu. Szczegó³owe zasady dotycz±ce parametrów stoku i sprzêtu okre¶la regulamin organizacji FIS (Federation International du Ski), z po¶ród których najbardziej istotnymi s±:

\begin{itemize}
\item minimalna i maksymalna ró¿nica wzniesieñ na trasie
\item minimalna i maksymalna odleg³o¶æ pomiêdzy kolejnymi bramkami
\item ilo¶æ bramek jaka powinna siê znale¼æ na trasie - proporcjonalnie do ró¿nicy wzniesieñ
\item wymagana d³ugo¶æ narty
\item wymagany promieñ skrêtu narty
\end{itemize}

Parametry te ró¿ni± siê w zale¿no¶ci od dyscypliny. Najbardziej techniczn± dyscyplin± jest slalom, nazywany wcze¶niej slalomem specjalnym. Techniczno¶æ tej dyscypliny polega na du¿ej ilo¶ci bramek znajduj±cych siê w niewielkiej odleg³o¶ci od siebie, co wymusza czêste skrêty. Zawodnicy je¿d¿± slalom na nartach o bardzo ma³ym promieniu skrêtu, rzêdu 11 metrów. Bramka w slalomie sk³ada siê z dwóch tyczek tego samego koloru. W slalomie gigancie, odleg³o¶ci miêdzy kolejnymi bramkami s± wiêksze, co implikuje szybsz± jazdê. Bramka w tej dyscyplinie sk³ada siê z czterech tyczek tego samego koloru, po dwie na ka¿dy koniec bramki. Dodatkowo ka¿de dwie tyczki z koñca bramki po³±czone s± p³acht± tego samego koloru co tyczki - czerwon± lub niebiesk±. Zawodnicy do tej dyscypliny u¿ywaj± nart o promieniu nawet 30 metrów. Kolejne dyscypliny s± jeszcze szybsze a promienie nart coraz wiêksze. Bramki zarówno w Super gigancie jak i Zje¼dzie, s± analogiczne do tych gigantowych, ró¿ni± siê tylko szeroko¶ci± p³acht. Super gigant, to bardziej \quotedblbase wypuszczony\textquotedblright slalom gigant, czyli slalom na którym odleg³o¶ci miêdzy bramkami s± ju¿ bardzo du¿e, a prêdko¶æ proporcjonalnie ro¶nie. Zjazd to ju¿ typowa dyscyplina szybko¶ciowa. Na trasie, zakrêty wynikaj± prawie tylko z konfiguracji terenu. Dodatkowo zdarzaj± siê na trasie elementy ukszta³towania terenu na których zawodnicy wybijaj± siê i skacz± po nawet 20 metrów.

Aby poprawnie przejechaæ przez bramkê na trasie, w ka¿dej z opisywanych wy¿ej dyscyplin, nale¿y przejechaæ pomiêdzy tyczkami wyznaczaj±cymi tzw. \textit{¶wiat³o bramki}. Bramki wymuszaj± skrêty, ale nie jest tak, ¿e ustawione s± zawsze rytmicznie tzn. wymuszaj±c skrêty raz w praw±, raz w lew± stronê o tym samym promieniu. Najczê¶ciej spotykanym rodzajem bramki jest tzw. \textit{bramka otwarta}. Bramka otwarta, charakteryzuje siê tym, ¿e ¶wiat³o bramki znajduje siê prostopadle do linii spadku stoku. Poza bramkami otwartymi, bramki mog± byæ ustawione w tzw. figury slalomowe. Pierwsz± z nich jest \textit{przelot} i mo¿e wystêpowaæ w ka¿dej z dyscyplin. Przelot polega na ustawieniu dwóch kolejnych bramek w taki sposób, ¿e nie wymuszaj± skrêtu pomiêdzy nimi. Przelot stosowany jest w celu adaptacji trasy przejazdu do konfiguracji terenu, np. gdy na trasie naturalnie wystêpuje d³u¿szy skrêt w jedn± ze stron lub napêdzeniu narciarza. Kolejn± figur±, stosowan± ju¿ tylko w slalomie, jest \textit{³okieæ}. £okieæ to dwie bramki ustawione w bliskiej odleg³o¶ci jedna pod drug± w linii spadku stoku. S± to bramki zamkniête, czyli ¶wiat³o bramki jest zgodne z lini± spadku stoku. Figura ta wprowadza zmianê rytmu i równie¿ pozwala na dostosowanie trasy do konfiguracji terenu. Ostatni± z figur, równie¿ stosowan± tylko w slalomie, jest \textit{wertikal}. Wertikal to bramki ustawione tak samo jak w wypadku ³okcia, czyli jedna pod drug±, w linii spadku stoku, z tym, ¿e zamiast dwóch, mo¿e byæ trzy, cztery czy nawet piêæ kolejno tak ustawianych bramek.

Opisanie wy¿ej wymienionych elementów, by³o istotne by zrozumieæ problem znajdowania optymalnej trasy. Najtrudniejsze jest bowiem optymalne przejechanie figur slalomowych. Podczas ogl±dania trasy, przed zawodami czy te¿ podczas treningów, zawodnicy zwracaj± du¿± uwagê na zapamiêtanie wystêpuj±cych po sobie figur i przewidywanie, na podstawie do¶wiadczenia, w jaki sposób nale¿y najechaæ na dan± figurê, by zmie¶ciæ siê, czy te¿ najszybciej pokonaæ kolejne, nastêpuj±ce po danej figurze bramki. Poprzez najazd na figurê, rozumiemy moment rozpoczêcia i sposób prowadzenia skrêtu przed figur±. Im wcze¶niej narciarz zrobi najazd, tym szybciej, po poprawnym przejechaniu bramki, bêdzie móg³ zmieniæ kierunek jazdy do kolejnych tyczek.

%---------------------------------------------------------------------------

\section{Fizyczny model narciarza}
\label{sec:fizycznyModel}


\subsubsection{Si³a oporu powietrza}

Si³a oporu powietrza jest przyk³adem si³y *****(\\TODO fluid friction). Zale¿no¶æ warto¶ci tej si³y od prêdko¶ci mo¿e byæ bardzo z³o¿ona i skomplikowana i tylko w specjalnych przypadkach mo¿e byæ rozwi±zana analitycznie. Dla bardzo ma³ych warto¶ci prêdko¶ci, dla ma³ych cz±stek, si³a oporu powietrza jest wprost proporcjonalna do prêdko¶ci, a zale¿no¶æ ta mo¿e byæ opisana równaniem:

\begin{equation}
F_d = v b
\end{equation}

v - prêdko¶æ narciarza

Dla wiêkszych prêdko¶ci i wiêkszych obiektów, si³a oporu powietrza jest w dobrym przybli¿eniu proporcjonalna do kwadratu prêdko¶ci i zale¿no¶æ t±, mo¿na opisaæ równaniem:


\begin{equation}
F_d = \frac{1}{2}C\rho Av^2
\end{equation}

C - wspó³czynnik oporu powietrza, typowe warto¶ci oscyluj± miêdzy 0.4 a 1

$\rho$ - gêsto¶æ powietrza w jednostce $kg m^{-3}$. Warto¶ci gêsto¶ci powietrza przy przeciêtnym ci¶nieniu wahaj± siê miêdzy 1.26 a 1.42 w zale¿no¶ci od temperatury.

A - frontalna powierzchnia narciarza w projekcji prostopad³ej do wektora prêdko¶ci narciarza wyra¿ona w $m^{2}$.

\begin{figure}[h]
\centering
\includegraphics{airDrag}
\end{figure}

Na grafice widzimy warto¶æ wspó³czynnika $A$ w zale¿no¶ci od pozycji narciarza. Grafika pochodzi z badañ prowadzonych w tunelu aerodynamicznym IAT we Francji, prowadzonych przez ***********\\TODO (Sport Aerodynamics: On the Relevance of Aerodynamic Force Modelling Versus Wind Tunnel Testing Caroline Barelle
National Technical University of Athens Greece)

Pozycja narciarza ma znacz±cy wp³yw na warto¶æ wspó³czynnika $A$. Przyjêcie pozycji zjazdowej redukuje w stosunku do pozycji podniesionej, warto¶æ wspó³czynnika nawet o jedn± trzeci±. Warto nadmieniæ równie¿, ¿e narciarze, nawet na amatorskich zawodach ubrani s± w specjalne kombinezony tzw. \textit{gumy narciarskie}. Kombinezony te s± jednoczê¶ciowe i ¶ci¶le przylegaj± do cia³a. Nie posiadaj± ¿adnych odstaj±cych elementów, czasami zawieraj± tylko wewnêtrzne ochraniacze w miejscach w których narciarz uderza przy ka¿dym skrêcie cia³em w tyczkê. Powodem dla którego strój ten jest tak popularny równie¿ w amatorskim sporcie jest fakt ¿e znacz±co mniejsza opór powietrza, w stosunku do klasycznego stroju narciarskiego i potrafi na kilkudziesiêciu sekundowej trasie, gdzie liczy siê ka¿da setna sekundy, redukowaæ czas przejazdu nawet o dziesiêtne czê¶ci sekundy.

\subsubsection{Interakcje miedzy ¶niegiem a nartami}

To, ¿e narty ¶lizgaj± siê na ¶niegu zawdziêczamy skomplikowanej fizyce interakcji miêdzy powierzchni± narty a ¶niegiem czy lodem. Ilo¶æ czynników jakie wp³ywaj± na jako¶æ tej interakcji jest bardzo du¿a, a z po¶ród nich warto wymieniæ:

\begin{itemize}
\item materia³ wykonania ¶lizgu narty
\item rodzaj, jako¶æ, sposób nak³adania i kolejno¶æ nak³adania smarów na ¶lizg narty
\item g³adko¶æ ¶lizgu narty
\item rodzaj i pochodzenie ¶niegu (naturalne/ sztuczne)
\item temperatura i stopieñ zanieczyszczenia ¶niegu
\item k±t nachylenia miêdzy ¶lizgiem a pod³o¿em
\end{itemize}


Jest jeszcze jeden czynnik wp³ywaj±cy na t± interakcjê, tzw. \textit{water suction} (w wolnym t³umaczeniu zasysanie wody). W temperaturze powy¿ej -3 stopni Celsjusza, ciep³o powstaj±ce na skutek tarcia, topi cienk± warstwê ¶niegu pod nartami. Aby zredukowaæ ten negatywnie wp³ywaj±cy na po¶lizg efekt, ¶lizg narty ma perforowan± strukturê, któr± nale¿y zachowywaæ i odkrywaæ po ka¿dym smarowaniu, aby odprowadzaæ wodê. 


Wed³ug badañ przeprowadzonych (THE SCIENCE OF SKI WAXES, Chris Talbot, ESA, http://www.nensa.net/equipment/TheScienceofSkiWaxes.pdf *** \\TODO), tarcie o ¶nieg ma du¿o wiêkszy wp³yw na czas przejazdu ni¿ si³y tarcia powietrza.

\subsubsection{Tarcie kinetyczne}
Tarcie kinetyczne ma du¿o wiêksze znaczenie ni¿ tarcie statyczne poniewa¿ determinuje jak du¿a si³a musi dzia³aæ, ¿eby zachowaæ porz±dan± prêdko¶æ podczas zjazdu. Wspó³czynnik tarcia kinetycznego miêdzy ¶niegiem a nasmarowanymi nartami wynosi ¶rednio 0.05. Wspó³czynnik ten jednak mo¿e siê znacz±co zmieniaæ i w zale¿no¶ci od rodzaju smarów, sposobu smarowania oraz jako¶ci ¶niegu wynosi miêdzy 0.001 a 0.3. Ró¿nica w warto¶ciach wspó³czynników ma prze³o¿enie w cenach smarów, które na warto¶ci tych wspó³czynników wp³ywaj±. Ju¿ na amatorskich zawodach, mo¿na zaobserwowaæ staranne przygotowanie ¶lizgów przed ka¿dym zjazdem i u¿ywanie smarów których cena wynosi nawet kilkaset z³otych, a które s± zu¿ywane w ci±gu jednego sezonu startów.  



\subsubsection{Interakcje miedzy ¶niegiem a nartami}
Wystepuj± cztery zasadnicze czynniki wp³ywaj±ce na prêdko¶
%---------------------------------------------------------------------------

\section{Metody numeryczne rozwi±zywania równañ ró¿niczkowych}
\label{sec:numeryka}


%---------------------------------------------------------------------------

\section{Optymalizacja}
\label{sec:optymalizacja}

W tym podrozdziale opisane s± metody optymalizacji u¿yte w zaproponowanym rozwi±zaniu, czyli algorytm ewolucyjny oraz algorytm optymalizacji lokalnej - Hill climbing.

% czym jest optymalizacja
Zadaniem optymalizacji jest przeszukanie przestrzeni rozwi±zañ w celu znalezienia takiego, które jest najlepsze. Zatem maj±c dan± funkcjê, nazywan± funkcj± celu, która ka¿demu punktowi reprezentuj±cemu rozwi±zanie problemu, poszukujemy takiego, dla którego warto¶æ tej funkcji bêdzie jak najmniejsza (b±d¼ jak najwiêksza). Trudno¶æ w znalezieniu takiego rozwi±zania zale¿y od charakteru funkcji celu, a czasem tak¿e od nieznajomo¶ci jej analitycznej postaci.

\subsubsection{Optymalizacja lokalna i globalna}
W przypadku funkcji z jednym optimum do znalezienia najlepszego rozwi±zania wystarczy przeszukiwanie lokalne. Polega ono na iteracyjnym sprawdzaniu rozwi±zañ w najbli¿szej przestrzeni i wprowadzaniu lokalnych zmian, aby w koñcu znale¼æ rozwi±zanie najlepsze w okolicy tzw. optimum lokalne. Je¶li wiemy, ¿e istnieje tylko jedno takie optimum, mo¿emy mieæ pewno¶æ, ¿e znalezione rozwi±zanie jest najlepszym w ca³ej przestrzeni rozwi±zañ. Przyk³adami optymalizacji lokalnych s±:
\begin{itemize}
\item hill climbing
\item przeszukiwanie tabu
\end{itemize}

Je¶li natomiast funkcja celu posiada wiele optimów lokalnych (tzw. funkcja wielomodalna) to optymalizacjê nazywamy optymalizacj± globaln±. Je¶li zadanie jest ci±g³e, a wiêc niemo¿liwe jest przeszukanie ca³ej przestrzeni rozwi±zañ, nigdy nie mo¿emy byæ pewni, ¿e zastosowany algorytm optymalizacji da nam rozwi±zanie najlepsze - byæ mo¿e bêdzie to tylko minimum lokalne a nie globalne. Nie maj±c takiej pewno¶ci nie wiemy kiedy nale¿y zatrzymaæ algorytm. Z tego powodu stosuje siê parametr steruj±cy czasem trwania obliczeñ, kosztem mniejszej pewno¶ci co do poprawno¶ci rozwi±zania mo¿emy otrzymaæ krótszy czas optymalizacji i odwrotnie.

\subsection{Algorytm ewolucyjny}
\label{sec:ewolucyjny}
Algorytm ewolucyjny jest przyk³adem algorytmu optymalizacyjnego, przeszukuj±cego przestrzeñ rozwi±zañ w celu znalezienia najlepszego rozwi±zania problemu. Algorytm ten oparty jest na obserwacjach ¶rodowiska i przystosowywania siê organizmów do jego warunków. Wiele terminów zapo¿yczonych jest zatem z genetyki.

Podstaw± ca³ego algorytmu jest populacja osobników, z których ka¿dy reprezentuje rozwi±zanie problemu. Populacja ta zmienia siê wraz z dzia³aniem algorytmu. Ewolucja zak³ada, ¿e populacja bêdzie siê sk³adaæ z coraz lepiej przystosowanych osobników. Przystosowanie to jest obliczane za pomoc± wcze¶niej okre¶lonej funkcji oceniaj±cej jako¶æ danego osobnika, czyli jak dobre jest rozwi±zanie reprezentowane przez niego. Przystosowanie jest warto¶ci± liczbow± obliczon± za pomoc± tej funkcji przystosowania.\\
Funkcja przystosowania okre¶la warto¶æ przystosowania osobnika na podstawie jego fenotypu, który jest tworzony z genotypu. Genotyp okre¶la zestaw cech danego osobnika i sk³ada siê z chromosomów (najczê¶ciej z jednego). Natomiast ka¿dy z chromosomów sk³ada siê z elementarnych jednostek - genów.\\

\subsubsection{Schemat dzia³a algorytmu ewolucyjnego}
Algorytm ewolucyjny rozpoczyna siê poprzez wygenerowanie populacji bazowej oraz obliczenie przystosowania jej osobników. Przewa¿nie osobniki te generowane s± ca³kowicie losowo, ale mo¿na tak¿e wprowadziæ konkretne osobniki np. o znanym dobrym przystosowaniu do ¶rodowiska.

G³ówna czê¶æ algorytmu opiera siê na powtarzaniu pêtli, w której wykonywane s± kolejno:

\begin{itemize}
\item reprodukcja
\item operacje genetyczne
\item ocena
\item sukcesja
\end{itemize}

Czêsto reprodukcjê i sukcesjê ³±czy siê pod nazw± selekcja.

Reprodukcja powoduje powielenie losowo wybranych osobników z populacji. Prawdopodobieñstwo wybrania osobnika do powielenia najczê¶ciej jest proporcjonalne do jego przystosowania. Mo¿e siê zdarzyæ, ¿e dany osobnik zostanie wybrany wiêcej ni¿ raz, a tak¿e, ¿e nie zostanie wybrany ani razu.\\
Nastêpnie na tych kopiach przeprowadzane s± operacje genetyczne powoduj±ce zmiany w genotypie osobników. Wyró¿niamy dwie podstawowe operacje:

\begin{itemize}
\item mutacja
\item krzy¿owanie
\end{itemize}

%---- WSTAWKA ANGIELSKA!!!!!!!!!!!!!!!!!--------
Zadaniem mutacji jest losowe zmodyfikowanie genów w genotypie.\\
Krzy¿owanie, zwane tak¿e rekombinacj± (ang. \textit{crossover}), dzia³a na co najmniej dwóch osobnikach i na podstawie ich genotypu tworzy jeden lub wiêcej osobników potomnych. Chromosomy rodzicielskie s± mieszane w celu otrzymania nowych genotypów dla osobników potomnych.

W wyniku operacji genetycznych powstaj± nowe osobniki, które wchodz± w sk³ad populacji potomnej. Ka¿dy z tych osobników jest oceniany za pomoc± funkcji przystosowania. Porównuj±c jako¶æ osobników z populacji bazowej oraz potomnej dokonuje siê sukcesji, czyli wyboru osobników z tych populacji (czasem wy³±cznie z populacji potomnej) i tworzy now± populacjê bazow±.

Zakoñczenie dzia³ania algorytmu przewa¿nie opiera siê na badaniu funkcji przystosowania ca³ej populacji. Je¶li warto¶æ przystosowania populacji nie jest zró¿nicowana mówimy o stagnacji algorytmu i mo¿e byæ to wskazaniem do zakoñczenia dzia³ania algorytmu. Czasem jednak oczekuje siê a¿ przystosowanie to bêdzie wystarczaj±co du¿e, ¿eby stwierdziæ, ¿e znalezione rozwi±zanie jest bardzo dobre. Przewa¿nie jednak nie znamy nawet przybli¿onej warto¶ci jako¶ci rozwi±zania, wiêc nie mo¿emy stwierdziæ kiedy przystosowanie jest odpowiednie i czy nie mo¿e siê jeszcze znacznie poprawiæ.

\subsubsection{Kodowanie osobników}
W przypadku algorytmów genetycznych, bêd±cych szczególnym przypadkiem algorytmów ewolucyjnych, do kodowania osobników stosuje siê kodowanie binarne chromosomów. Pojedynczy bit reprezentuje zatem gen nale¿±cy do chromosomu.\\
W takim przypadku mutacja wykonywana jest na ka¿dym genie osobno z pewnym prawdopodobieñstwem, je¶li do niej dochodzi, zmienia siê warto¶æ bitu na przeciwn±. W krzy¿owaniu wybiera siê dwa osobniki rodzicielskie, których chromosomy rozcinane s± na dwie czê¶ci i ³±czone "na krzy¿". Miejsce przeciêcia jest losowane z rozk³adem równomiernym.

W algorytmach ewolucyjnych porzuca siê kodowanie binarne - chromosom sk³ada siê z jednej lub wiêcej liczb stanowi±cych cechy osobnika.\\
Mutacja takiego osobnika najczê¶ciej odbywa siê poprzez losow± zmianê ka¿dej z warto¶ci genów chromosomu. Do krzy¿owania wybiera siê dwa osobniki, z których dla ka¿dej pary odpowiadaj±cych genów wyci±gana jest ¶rednia i tak otrzymane warto¶ci genów tworz± genotyp nowego osobnika.

\subsubsection{Typy algorytmów ewolucyjnych}
Algorytmy ewolucyjne wywodz± siê z kilku osobnych nurtów zajmuj±cych siê t± tematyk±, wiêc istnieje wiele podobnych schematów. Najlepiej traktowaæ algorytmy ewolucyjne jako metaheurystykê - okre¶lony jest pewien szkic algorytmu, który mo¿na dostosowywaæ do konkretnego rozwi±zania. W tym podrozdziale opisane s± podstawowe i najbardziej popularne schematy postêpowania oparte o algorytmy ewolucyjne.

\paragraph{Prosty algorytm genetyczny}

Prosty algorytm genetyczny zosta³ zaproponowany w roku 1975 przez John'a Holland'a.

Maj±c populacjê bazow± $P^t$ dokonujemy reprodukcji tej populacji, tworz±c populacjê tymczasow± $T^t$ sk³adaj±c± siê z takiej samej liczby osobników. Wybierani s± oni z prawdopodobieñstwem proporcjonalnym do ich przystosowania z populacji bazowej. Na populacji tymczasowej dokonujemy operacji genetycznych (mutacji i krzy¿owania). Do krzy¿owania wybierane s± roz³±czne pary osobników i z pewnym prawdopodobieñstwem $p_c$ zachodzi ich skrzy¿owanie. Je¶li dosz³o do powstania osobników potomnych zastêpuj± one osobniki rodzicielskie. Nastêpnie na tak otrzymanej populacji tymczasowej dochodzi do mutacji osobników i otrzymania populacji potomnej $O^t$. Ta populacja staje siê w nastêpnej iteracji algorytmu now± populacj± bazow±.\\
Zatrzymanie algorytmu mo¿e byæ dokonane je¶li np.:

\begin{itemize}
\item wykonano okre¶lon± z góry liczbê iteracji
\item znaleziono osobnika o wystarczaj±co wysokiej warto¶ci przystosowania
\end{itemize}

W tej wersji algorytmu czêsto pêtlê algorytmu nazywa siê generacj±, a ka¿d± populacjê $P^t$ w chwili t pokoleniem.\\

\paragraph{Strategia (1+1).}

Strategia (1+1) jest podstawow± strategii ewolucyjnych. W algorytmie tym mamy do czynienia z populacj± sk³adaj±c± siê z tylko jednego osobnika posiadaj±cego jeden chromosom. W ka¿dej pêtli algorytmu dokonuje siê mutacji tego chromosomu, co powoduje powstanie nowego osobnika. Osobnik ten jest poddawany ocenie, a nastêpnie dokonuje siê wyboru lepszego z dwóch istniej±cych osobników i tego pozostawia w populacji.\\
W mutacji dodaje siê do ka¿dego genu chromosomu losow± modyfikacjê rozk³adem normalnym:
\begin{equation}
Y^t_i = X^t_i + \sigma\xi_{N(0,1),i}
\end{equation}

Warto¶æ $\sigma$ bêdzie powodowa³a wiêksze lub mniejsze zmiany w chromosomie. Je¶li chcemy przeszukaæ przestrzeñ, powinni¶my zwiêkszaæ jej warto¶æ, co jest po¿±dane zw³aszcza w pocz±tkowej fazie dzia³ania algorytmu. Natomiast, aby znale¼æ jak najlepsze rozwi±zanie, wiedz±c ¿e obecne rozwi±zanie jest ju¿ bardzo bliskie najlepszemu, mo¿emy zmniejszaæ warto¶æ $\sigma$ przeszukuj±c tylko najbli¿sz± przestrzeñ.\\
Do wyznaczania $\sigma$ powsta³ nastêpuj±cy algorytm zwany regu³± 1/5 sukcesów:
\begin{enumerate}
\item Je¶li przez kolejnych k pêtli algorytmu mutacja powoduje powstanie lepszego osobnika w wiêcej ni¿ 1/5 wszystkich mutacji, to zwiêkszamy $\sigma$: $\sigma' = c_i \sigma$. Warto¶æ $c_i$ wyznaczona empirycznie wynosi $ \frac{1}{0.82} $
\item Gdy dok³adnie 1/5 koñczy siê sukcesem, warto¶æ $\sigma$ pozostaje bez zmian.
\item Je¶li nie zachodzi ¿adne z powy¿szych warto¶æ $\sigma$ jest zmniejszana: $\sigma' = c_d \sigma$. Gdzie $ c_d $ powinna wynosiæ $ 0.82 $
\end{enumerate}

\paragraph{Strategia ($\mu$ + $\lambda$).}

Strategia ($\mu$ + $\lambda$) jest rozwiniêciem strategii (1+1). $\mu$ oznacza ilo¶æ osobników w populacji pocz±tkowej, a $\lambda$ ile osobników jest reprodukowanych i poddawanych operacjom genetycznym. Dodatkowo, zamiast regu³y 1/5 sukcesów wprowadzono mechanizm samoczynnej adaptacji zasiêgu mutacji, a tak¿e wprowadzono operator krzy¿owania.

Oznaczenie $\mu$ + $\lambda$ oznacza, ¿e po wygenerowaniu populacji potomnej wybierane jest $\mu$ najlepszych osobników do nowej populacji bazowej - zarówno spo¶ród populacji potomnej, jak i starej populacji bazowej zawieraj±cej ³±cznie $\mu$ + $\lambda$ osobników.

W strategii tej wa¿ne jest te¿ kodowanie, do którego dodatkowo do³o¿ono równie¿ chromosom przechowuj±cy wektor $\sigma$ zawieraj±cy warto¶ci odchyleñ standardowych, które wykorzystuje siê w trakcie mutacji.\\
Po wylosowaniu warto¶ci zmiennej losowej o rozk³adzie normalnym ($\xi_{N(0,1)}$) dla ka¿dego elementu wektora $\sigma$ losujemy jeszcze jedn± zmienn± losow± o rozk³adzie normalnym ($\xi_{N(0,1),i}$) i oblicza nowe warto¶ci odchyleñ z wektora $\sigma$:

\begin{equation}
\sigma'_i = \sigma_i e^{(\tau'\xi_{N(0,1)} + \tau\xi_{N(0,1),i})}
\end{equation}

%--------CO Z K i n??-------
Gdzie $\tau$ oraz $\tau'$ s± parametrami algorytmu, a ich warto¶ci powinny wynosiæ:
\begin{equation}
\tau = \frac{K}{\sqrt{2n}}
\end{equation}

\begin{equation}
\tau' = \frac{K}{\sqrt{2\sqrt{n}}}
\end{equation}

Maj±c dane nowe warto¶ci odchyleñ standardowych mo¿emy obliczyæ nowe warto¶ci genów korzystaj±c ze wzoru:

\begin{equation}
X'_i = X_i + \sigma'_i\xi_{N(0,1),i}
\end{equation}
gdzie $\xi_{N(0,1),i}$ jest now± losow± warto¶ci±.

Algorytm ewolucyjny wybiera osobniki lepiej przystosowane, a wiêc te, które posiadaj± tak¿e lepsze warto¶ci odchyleñ standardowych. Powoduje to naturaln± selekcjê, doprowadzaj±c± do samoczynnej adaptacji odchyleñ standardowych stosowanych w trakcie mutacji.

Krzy¿owanie wystêpuje w tym algorytmie pod nazw± rekombinacja. Najczê¶ciej sprowadza siê do u¶rednienia lub wymianie warto¶ci wektorów, tak¿e wektora $\sigma$.

\paragraph{Strategia ($\mu$, $\lambda$).}
Strategia ($\mu$ + $\lambda$) posiada pewne wady, które postanowiono spróbowaæ wyeliminowaæ za pomoc± nowej strategii ($\mu$, $\lambda$). Poprzedni algorytm sprawia problemy je¶li w populacji pojawia siê osobnik o wysokiej warto¶ci przystosowania, ale posiadaj±cy zbyt du¿e (albo zbyt ma³e) warto¶ci odchyleñ standardowych. Usuniêcie takiego osobnika z populacji czêsto nie jest procesem krótkotrwa³ym, gdy¿ wp³ywa on na powstaj±ce potomstwo, przekazuj±c mu podobne do jego, nieodpowiednie warto¶ci odchyleñ.\\
W nowej strategii wprowadzono zmianê, która powoduje, ¿e osobniki rodzicielskie nie s± nigdy brane do kolejnej populacji bazowej. Podczas selekcji korzysta siê zatem tylko z powsta³ej populacji potomnej, z niej wybieraj±c osobniki do populacji bazowej w kolejnej iteracji.

\subsection{Hill climbing}
\label{sec:hill}
Algorytm hill climbing jest jedn± z metod przeszukiwania lokalnego. W ka¿dej iteracji zmieniaj±c warto¶æ jednej ze zmiennych rozwi±zania sprawdzana jest warto¶æ funkcji celu dla nowego rozwi±zania i je¶li warto¶æ ta jest lepsza od dotychczas najlepszej znalezionej, zapamiêtujemy zmienione rozwi±zanie. Dopóki zmiany powoduj± poprawê rozwi±zania, algorytm nie jest zatrzymywany. Na koñcu wiemy, ¿e znalezione rozwi±zanie jest rozwi±zaniem lokalnie optymalnym.\\
Przeszukiwanie przestrzeni dyskretnej sprowadza siê do sprawdzenia rozwi±zañ najbli¿szych obecnemu i wybieranie tego rozwi±zania, którego warto¶æ obliczona za pomoc± funkcji celu jest najlepsza. Je¶li w¶ród s±siadów nie ma ju¿ lepszego rozwi±zania, mo¿emy zakoñczyæ przeszukiwanie.\\
W przestrzeni ci±g³ej konieczne jest dobranie kroku, który wyznacza punkty przeszukiwane w okolicy w trakcie ka¿dej iteracji. Dodatkowo wykorzystywane jest tzw. przyspieszenie (ang. \textit{acceleration}), które wyznacza piêciu mo¿liwych kandydatów na lepsze rozwi±zania. Najczê¶ciej przyspieszenie to wynosi 1.2, a warto¶æ kroku jest osobna dla ka¿dej zmiennej rozwi±zania i czêsto wynosi na pocz±tku 1. Zatem za ka¿dym razem obliczane s± nastêpuj±ce wspó³czynniki: -acceleration, -1/acceleration, 0, 1/acceleration, acceleration. Nastêpnie wspó³czynniki mno¿one s± przez krok (step) i dodawane do obecnie analizowanej zmiennej i wybierane jest najlepsze z piêciu rozwi±zañ. Warto¶æ kroku jest indywidualna dla ka¿dej zmiennej. Po wybraniu najlepszego rozwi±zania uaktualniana jest warto¶æ tego kroku - krok mno¿ony jest przez odpowiedni wspó³czynnik, ten który by³ dobrany wcze¶niej do znalezienia tego najlepszego rozwi±zania. Algorytm zatrzymywany jest je¶li zmiana ¿adnej ze zmiennych nie przynosi ju¿ poprawy rozwi±zania, czasem równie¿ je¶li ta zmiana jest ju¿ bardzo ma³a - wprowadzany jest parametr $\epsilon$ wyznaczaj±cy tê ró¿nicê.

%---------------------------------------------------------------------------

\section{Uczenie maszynowe}
\label{sec:maszynowe}

Uczeniem siê systemu jest ka¿da autonomiczna zmiana w systemie zachodz±ca na podstawie do¶wiadczeñ, która prowadzi do poprawy jako¶ci jego dzia³ania. (Cichosz)

Program siê uczy z do¶wiadczenia E dla zadañ T i miary jako¶ci P je¶li jego efektywno¶æ w zadaniach z T mierzona P wzrasta z do¶wiadczeniem E. (Mitchell)

Istnieje wiele rodzajów uczenia maszynowego. Podstawowy podzia³ wynika z rodzaju informacji trenuj±cej na:

\begin{itemize}
\item uczenie z nadzorem
\item uczenie bez nadzoru
\end{itemize}

W uczeniu siê z nadzorem ¼ród³em informacji trenuj±cej jest nauczyciel. Od niego otrzymuje uczeñ informacjê jakie zachowanie jest po¿±dane. Natomiast w przypadku uczenia bez nadzoru uczeñ dowiaduje siê o skuteczno¶ci swojego dzia³ania obserwuj±c wyniki - nazywa siê to czasem wbudowanym nauczycielem.

Istniej± jeszcze dwie grupy, które trudno zakwalifikowaæ do powy¿szych:

\begin{itemize}
\item uczenie siê na podstawie zapytañ
\item uczenie siê przez eksperymentowanie
\item uczenie siê ze wzmocnieniem
\end{itemize}

Do pierwszej z nich nale¿± algorytmy polegaj±ce na zadawaniu pytañ przez ucznia nauczycielowi. Natomiast do drugiej te, w których uczeñ gromadzi swoje do¶wiadczenia obserwuj±c konsekwencje swojego dzia³ania w ¶rodowisku. Uczenie siê ze wzmocnieniem jest podobne do tej metody, ale dodatkowo istnieje krytyk, który s³u¿y jako dodatkowe ¼ród³o informacji trenuj±cej. Jego zadaniem jest karanie b±d¼ nagradzanie ucznia za jego zachowanie. Uczeñ nie dowiaduje siê co ma robiæ, ale jak warto¶ciowe jest dane dzia³anie.

Czasem granice pomiêdzy tymi grupami s± nieostre i przynale¿no¶æ algorytmu do jakiej¶ grupy mo¿e zale¿eæ wy³±cznie od punktu widzenia.

\subsection{Uczenie siê ze wzmocnieniem}
\label{subsec:wzmocnienie}
W przypadku uczenia siê ze wzmocnieniem zadaniem ucznia jest obserwacja stanów ¶rodowiska, wykonywanie akcji oraz obserwowanie efektów tych akcji poprzez warto¶æ otrzymywanego wzmocnienia jako rzeczywistoliczbowej nagrody. Tak jak zosta³o to napisane wcze¶niej, w tym przypadku nie mówimy o nauczycielu, ale o krytyku, który warto¶ciuje zachowanie poprzez dostarczanie wzmocnienia. Zadaniem ucznie jest odnalezienie takiego zachowania, które przyniesie mu jak najwiêksz± nagrodê. Najczê¶ciej uczeñ nie ma pojêcia o tym jakie jest ¶rodowisko, czêsto niedeterministyczne, dlatego musi wchodziæ w interakcjê z nim, aby je poznaæ.

\begin{figure}[h]
\centering
\includegraphics{uczenie}
\end{figure}

W ka¿dym kroku uczeñ jest w okre¶lonym stanie ¶rodowiska. Decyduj±c siê na okre¶lon± akcjê otrzymuje informacjê o nowym stanie, w którym znajduje siê po wykonaniu tej akcji oraz o nagrodzie (wzmocnieniu) jak± otrzymuje za swoje dzia³anie. Uczeñ obserwuj±c nagrody otrzymywane za swoje zachowanie mo¿e uczyæ siê jak postêpowaæ, aby by³y one jak najwy¿sze.

Schemat algorytmu przedstawia siê nastêpuj±co:\\
Dla kolejnych kroków czasowych t: 
\begin{enumerate}
\item obserwujemy stan $x_t$
\item wybieramy akcjê $a_t$ mo¿liw± do wykonania w stanie $x_t$
\item wykonujemy akcjê $a_t$
\item obserwujemy wzmocnienie $r_t$ i nastêpny stan $x_{t+1}$
\item uczymy siê na podstawie do¶wiadczenia ($x_t,a_t,r_t,x_{t+1}$)
\end{enumerate}
Wybór akcji w kroku 2. dokonywany jest autonomicznie przez ucznia. Natomiast stan, do którego przechodzi po wykonaniu akcji jest okre¶lony przez ¶rodowisko na podstawie stanu poprzedniego oraz wykonanej akcji. Warto jednak zwróciæ uwagê na fakt, ¿e ¶rodowisko mo¿e byæ stochastyczne - wykonanie dwa razy tej samej akcji mo¿e dawaæ ró¿ne rezultaty. Poza tym, przewa¿nie ¶rodowisko jest nieznane uczniowi, st±d konieczno¶æ podejmowania prób i b³êdów poprzez wykonywanie ró¿nych akcji. Jednocze¶nie, uczeñ nie mo¿e wp³ywaæ na ¶rodowisko w ¿aden sposób.

\subsubsection{Strategia maksymalizacji nagród}
Nauka ucznia oparta jest na nagrodach, które otrzymuje za swoje dzia³ania. Musi znale¼æ on najlepsz± strategiê wyboru akcji, aby uzyskiwaæ jak najlepsze nagrody. Najczê¶ciej uczeñ próbuje maksymalizowaæ swoje nagrody d³ugoterminowo. Strategia ta polega na tym, ¿e nagrody za poprawne dzia³anie mog± przyj¶æ wiele kroków pó¼niej ni¿ wtedy gdy ono zosta³o wykonane. Strategia ta nazywana jest uczeniem siê z opó¼nionym wzmocnieniem. W uczeniu z natychmiastowym wzmocnieniem interesuje nas tylko maksymalizacja nagród tu¿ po danym zachowaniu. Nie jeste¶my wtedy w stanie braæ pod uwagê tego, jakie w przysz³o¶ci mog± byæ jego skutki.\\
W przypadku opó¼nionego wzmocnienia wprowadza siê wspó³czynnik dyskontowania $\gamma \in [0,1]$. Zadaniem ucznia jest zmaksymalizowanie zdyskontowanej sumy nagród:

\begin{equation}
\label{dyskont}
E[\sum_{t=0}^\infty \gamma^tr_t]
\end{equation}

Im wspó³czynnik $\gamma$ jest bli¿szy 0, tym bardziej maksymalizuje siê tylko natychmiastowe nagrody. Je¶li $\gamma = 1$ to maksymalizowana jest suma wszystkich otrzymanych nagród.

\subsubsection{Zadania epizodyczne}
W niektórych przypadkach dzia³ania ucznia mo¿na ³atwo wydzieliæ na niezale¿ne epizody, z których ka¿dy trwa najczê¶ciej skoñczon± liczbê kroków. Rozdzia³ ten jest kierowany tym, ¿e ka¿da z tych prób jest oceniania osobno. Zatem maksymalizujemy kryterium jako¶ci w ka¿dej próbie oddzielnie. Zatem w równaniu \ref{dyskont} musimy zast±piæ sumê nieskoñczon± otrzymuj±c:

\begin{equation}
E[\sum_{t=0}^{n-1} \gamma^tr_t]
\end{equation}

Warto¶æ $n$ to liczba kroków epizodu. Powy¿sze równanie mo¿na traktowaæ tak naprawdê jako szczególny przypadek równania \ref{dyskont}. Zak³adaj±c, ¿e w ostatnim kroku wchodzimy do stanu, w którym jedyna mo¿liwa akcja prowadzi z powrotem do niego, a nagroda w tym stanie wynosi 0, otrzymujemy dok³adnie powy¿sze równanie. W równaniu tym zmienna $r_t$ powinna byæ dla u¶ci¶lenia zast±piona przez $r_{i,t}$, poniewa¿ warto¶ci wzmocnienia mog± byæ ró¿ne w ka¿dej próbie $i$.

Istniej± tak¿e dwa szczególnego rodzaju typy zadañ epizodycznych, które nazywane s± zadaniami do-sukcesu lub do-pora¿ki. Zakoñczenie ka¿dej próby koñczy siê odpowiednio w ka¿dym typie sukcesem lub pora¿k±. W przypadku zadañ do-sukcesu chcemy, aby w ka¿dym epizodzie w jak najmniejszej liczbie kroków osi±gn±æ pewien po¿±dany stan, co powoduje osi±gniêcie sukcesu i zakoñczenie tej próby. Odpowiednio dla zadañ do-pora¿ki jak najbardziej chcemy odwlec moment przej¶cie do niepo¿±danego stanu, który oznacza pora¿kê.

\subsubsection{Algorytm uczenia siê strategii}
\paragraph{Q-learning.}
Algorytm Q-learning jest najczê¶ciej stosowanym algorytmem do uczenia siê optymalnej strategii. Uczenie siê polega na oszacowaniu optymalnej funkcji warto¶ci akcji. W ka¿dy kroku czasowym obliczana jest warto¶æ nastêpuj±cego wyra¿enia, które nazywane jest b³êdem:

\begin{equation}
\Delta = r_t + \gamma\max_aQ_t(x_{t+1},a) - Q_t(x_t,a_t);
\end{equation}

$r_t$ to warto¶æ wzmocnienia w tym kroku czasowym, nastêpny cz³on okre¶la maksymaln± warto¶æ funkcji $Q$ dla stanu, w którym znajdzie siê uczeñ po wykonaniu wybranej wcze¶niej przez siebie akcji. Tê warto¶æ mno¿ymy przez wspó³czynnik dyskontowania $\gamma$ i od tak obliczonej liczby odejmujemy obecn± warto¶æ funkcji dla obecnego stanu i wybranej akcji.\\
Aktualizacja warto¶ci funkcji odbywa siê w nastêpuj±cy sposób:

\begin{equation}
Q_{t+1}(x_t,a_t) = Q_t(x_t,a_t) + \alpha\Delta
\end{equation}

Dwa warunki dotycz±ce warto¶ci $\alpha$ powinny byæ spe³nione:

\begin{equation}
\sum_{i=1}^\infty\frac{1}{\alpha_i(x,a)} = \infty
\end{equation}
\begin{equation}
\sum_{i=1}^\infty\frac{1}{\alpha_i^2(x,a)} < \infty
\end{equation}

Jednak najczê¶ciej w praktyce rzadko stosuje siê do tych warunków.

Warto zwróciæ uwagê na fakt, ¿e nie okre¶lono tu w jaki sposób uczeñ rzeczywi¶cie wybiera akcjê. Nie musi to byæ wcale strategia, w której zawsze wybierana jest najlepsza z akcji.

\paragraph{Algorytm Sarsa.}
Algorytm Sarsa niewiele ró¿ni siê od algorytmu Q-learning. Jedyn± ró¿nic± jest modyfikacja wyra¿enia na b³±d:

\begin{equation}
\Delta = r_t + \gamma Q_t(x_{t+1},a_{t+1}) - Q_t(x_t,a_t);
\end{equation}

Zamiast wykorzystywaæ maksymaln± warto¶æ funkcji w przysz³ym stanie, korzystamy z warto¶ci, która faktycznie zostanie wybrana. Poniewa¿ wybór ten dokonywany jest dopiero w nastêpnym kroku, ogólny schemat musi byæ lekko zmodyfikowany. Ró¿nica ta powoduje, ¿e algorytm Sarsa nie posiada w³asno¶ci algorytmu Q-learning dotycz±cego wyboru akcji. Maksymalizacja dokonywana jest z u¿yciem tej samej strategii, z której korzysta algorytm.

\subsubsection{Wybór akcji}
Tak jak w przypadku algorytmów ewolucyjnych konieczna jest eksploracja ¶rodowiska, w którym znajduje siê uczeñ. Z drugiej jednak strony chcemy jak najszybciej znale¼æ optymalne zachowanie, czyli dokonaæ eksploatacji wiedzy, któr± ju¿ posiadamy. Pojawia siê pytanie w jaki sposób wybieraæ akcjê, aby dobrze poznaæ ¶rodowisko, a jednocze¶nie nie zmarnowaæ zbyt du¿o czasu na bezcelowe przeszukiwanie opcji, które nie daj± korzystnego rozwi±zania.\\
W przypadku algorytmów takich jak Q-learning, w których mo¿na u¿yæ innej strategii wyboru akcji ni¿ ta, która jest u¿ywana w trakcie maksymalizacji funkcji $Q$, zapewnienie eksploracji mo¿na zapewniæ stosuj±c jednostajnie losowy wybór akcji.

% wg http://webdocs.cs.ualberta.ca/~sutton/book/ebook/node16.html 
% http://webdocs.cs.ualberta.ca/~sutton/book/ebook/node17.html
Najprostszym sposobem wyboru akcji jest wybranie najlepszej z mo¿liwych akcji, nazywane strategi± zach³ann±, jednak metoda ta uniemo¿liwia eksploracjê. Aby to umo¿liwiæ, wprowadza siê modyfikacjê, która polega na tym, ¿e co jaki¶ czas z prawdopodobieñstwem $\epsilon$ stosuje siê wspomniany wcze¶niej jednostajnie losowy wybór akcji. Strategia ta nazywana jest strategi± $\epsilon$-zach³ann±. Metoda ta jest znana jako dobrze równowa¿±ca zadania eksploracji i eksploatacji.

Minusem strategii $\epsilon$-zach³annej jest to, ¿e w trakcie eksploracji ka¿da z akcji jest losowana z takim samym prawdopodobieñstwem. Aby wyeliminowaæ ten element, stosuje siê metody selekcji nazywane \textit{softmax}. Wszystkie akcje mog± zostaæ wylosowane, ale z prawdopodobieñstwem odpowiadaj±cym im dotychczasowej warto¶ci. Najczê¶ciej korzysta siê z rozk³adu Gibbs'a lub Boltzmann'a. Prawdopodobieñstwo wybrania akcji $a$ w próbie $t$ wynosi:

\begin{equation}
\frac{\epsilon^{Q_t(a)/\tau}}{\sum_{b=1}^n\epsilon^{Q_t(b)/\tau'}}
\end{equation}

Parameter $\tau$ nazywany jest temperatur±. Im jest ona wy¿sza, tym wybór dowolnej akcji jest bardziej losowy. W przypadku temperatur bliskich 0 wybór praktycznie jednoznacznie padnie na akcjê o najwy¿szej warto¶ci funkcji $Q$. 

\section{Volunteer Computing}
\label{volunteerComputing}

Volunteer computing to nieformalny kontrakt w którym zwykli ludzie czy te¿ organizacje, nazywani dalej ochotnikami, dobrowolnie udostêpniaj± swoje zasoby obliczeniowe by uruchamiaæ na nich obliczenia zwi±zane z ró¿norakimi projektami. Projekty to, przewa¿nie projekty naukowe, których celem jest rozwi±zanie problemów i zadañ matematycznych czy te¿ problemów dotykaj±cych ludzko¶æ, lub d±¿±cych do lepszego poznania ¶wiata i wszech¶wiata. Dziêki platform± umo¿liwiaj±cym Volunteer computing, ka¿dy cz³owiek mo¿e w niewielkim stopniu kontrybuowaæ w rozwi±zywaniu tych problemów.

Ochotnicy to osoby prywatne albo instytucje takie jak szko³y czy uniwersytety. Ochotnicy przewa¿nie pozostaj± anonimowi, choæ w niektórych projektach wymagane jest dostarczenie podstawowych danych kontaktowych jak np. adresu email. W wypadku celowego dostarczania b³êdnych wyników przez ochotnika, utrudnione jest jego dyscyplinowanie czy te¿ wy³±czenie z projektu. Ochotnicy nie s± wynagradzani finansowo za uczestnictwo w projekcie. 

Organizacja czy osoba chc±ca wykorzystaæ model Volunteer computing do swoich projektów, musi byæ jednostk± zaufan± dla ochotników realizuj±cych obliczenia. Wynika to z prostego faktu, ¿e ochotnicy decyduj± siê, wed³ug standardowego modelu computing,  na zainstalowanie aplikacji dostarczanej przez dawcê zadañ obliczeniowych. Osoba instaluj±ca aplikacjê musi ufaæ, ¿e nie uszkodzi ona jej komputera ani te¿ nie bêdzie wykorzystywaæ jej zasobów w sposób niezgodny z zapewnieniami zleceniodawcy obliczeñ. Zleceniobiorca obliczeñ ma te¿ prawo oczekiwaæ, ¿e aplikacja, zosta³a napisana przestrzegaj±c dobrych praktyk bezpieczeñstwa, gdy¿ jako, ¿e aplikacja ta ³±czy siê z internetem i potencjalnie jest zainstalowana na du¿ej ilo¶ci maszyn wiêc jest atrakcyjnym celem ataków zmierzaj±cych do przejêcia  tych maszyn do niezgodnych z prawem celów przez hakerów. 

Przewa¿nie model komunikacyjny systemu Volunteer Computing uwzglêdnia tylko komunikacje poszczególnych klientów z centralnym serwerem i nie zak³ada bezpo¶redniej komunikacji miêdzy klientami.

Volunteer Computing pierwotnie zak³ada³, ¿e obliczenia s± wykonywane na zwyk³ych PC-tach. Ilo¶æ komputerów tego typu jest nieporównywalnie wiêksza do ilo¶ci wyspecjalizowanych komputerów o du¿ej mocy obliczeniowej i jest szacowana na ponad miliard. Dodatkowa, z przyczyn ekonomicznych, na rozwój tych maszyn producenci sprzêtu przeznaczaj± najwiêksze fundusze wiêc ich moc i zdolno¶ci obliczeniowe stale rosn±. 

Wa¿nym aspektem, który istotnie wp³ywa na stosowanie modelu w praktyce jest koszt prowadzenia obliczeñ. Model zak³ada, ¿e do³±czanie siê do obliczeñ jest ochotnicze i nie dostaje siê za uczestnictwo w projekcie wynagrodzenia. Dziêki temu, projekty, które maj± poparcie i akceptacjê spo³eczn± mog± liczyæ na darmowe moce obliczeniowe udostêpnione przez zwyk³ych ludzi.

Na ten model mo¿na patrzyæ tak¿e w kategoriach edukacyjnych. Podczas gdy ochotnik przystêpuje do projektu i udostêpnia swoje moce obliczeniowe, mo¿na wykorzystaæ jego potencjalne zainteresowanie rozwi±zywanym problemem i za pomoc± przystêpnych wizualizacji przedstawiæ mu sedno rozwi±zywanego zadania, nakre¶liæ mu problem z ró¿nych perspektyw i pokazaæ mu do czego potencjalnie zmierzaj± obliczenia. Po³±czenie atrakcyjnej formy t³umaczenia rozwi±zywanych problemów z potencja³em portali spo³eczno¶ciowych i wiralno¶ci ciekawego materia³u mo¿na uzyskaæ daleko id±cy efekt propagacji i pod³±czaniu siê do obliczeñ coraz wiêkszej ilo¶ci osób.

\section{Web Workers}
\label{webWorkers}

Przeprowadzanie intensywnych obliczeñ w przegl±darkach internetowych nie by³o mo¿liwe do czasu wprowadzenia przez  grupê WHATWG (Web Hypertext Application Technology Working Group) specyfikacji Web Worker. Ograniczenie wynika³o z faktu, ¿e jêzyk w którym wykonywane s± skrypty poprzez silniki przegl±darki to Java Script. Java Script to ¶rodowisko jednow±tkowe, wiêc nic nie mo¿e byæ wykonywane równolegle. Zlecaj±c wiêc skryptowi intensywne obliczenia, na ich czas ca³y UI strony by³by nieresponsywny, co jest nie do przyjêcia dla cz³owieka obs³uguj±cego stronê internetow±. Przegl±darki broni± u¿ytkownika przed takim zachowaniem skryptów na stronie i czasami zdarza siê jeszcze zobaczyæ okno z ostrze¿eniem, ¿e skrypt przesta³ odpowiadaæ i mo¿liwo¶ci± manualnego zatrzymania skryptu.

Web Workers definiuje API do tworzenia osobnych procesów w tle. Workery wykorzystuj± do komunikacji z w±tkiem g³ównym klasyczny model przekazywania wiadomo¶ci. Nowoczesne przegl±darki umo¿liwiaj± przekazywanie zarówno tekstu jak i obiektów zserializowanych jako JSONy. Nale¿y zwróciæ uwagê, ¿e obiekty te nie s± wspó³dzielone ale w pe³ni kopiowane. 

Web Workery nie ma j± dostêpu do struktury DOM, obiektu \textit{window} ani \textit{document}. Zewnêtrzne skrypty wykorzystywane przez workera musz± byæ serwowane z tej samej domeny co kod workera.

Wed³ug specyfikacji, stworzonej przez WHATWG, Web Workery powinny byæ u¿ywane do zadañ trwaj±cych d³u¿szy czas, maj±cych du¿y narzut startowy i spory narzut pamiêciowy. Nie s± wiêc odpowiednie tworzenie bardzo wielu workerów zajmuj±cych siê obliczeniami trwaj±cymi marginalny czas, gdy¿ sam narzut na stworzenie przez przegl±darkê osobnego procesu mo¿e byæ zbyt du¿y by uzasadniæ jego u¿ycie.
