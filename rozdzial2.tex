\chapter{Wprowadzenie teoretyczne}
\label{cha:wstepTeoretyczny}

W rozdziale tym przedstawiono informacje .

%---------------------------------------------------------------------------

\section{Fizyczny model narciarza}
\label{sec:fizycznyModel}

%---------------------------------------------------------------------------

\section{Metody numeryczne rozwi±zywania równañ ró¿niczkowych}
\label{sec:numeryka}


%---------------------------------------------------------------------------

\section{Optymalizacja}
\label{sec:optymalizacja}

W tym podrozdziale opisane s± metody optymalizacji u¿yte w zaproponowanym rozwi±zaniu, czyli algorytm ewolucyjny oraz algorytm optymalizacji lokalnej - Hill climbing.

% czym jest optymalizacja
Zadaniem optymalizacji jest przeszukanie przestrzeni rozwi±zañ w celu znalezenia takiego, które jest najlepsze. Zatem maj±c dan± funkcjê, nazywan± funkcj± celu, która ka¿demu punktowi reprezentuj±cemu rozwi±zanie problemu, poszukujemy takiego, dla którego warto¶æ tej funkcji bêdzie jak najmniejsza (b±d¼ jak najwiêksza). Trudno¶æ w znalezieniu takiego rozwi±zania zale¿y od charakteru funkcji celu, a czasem tak¿e od nieznajomo¶ci jej analitycznej postaci.

\subsubsection{Optymalizacja lokalna i globalna}
W przypadku funkcji z jednym optimum do znalezienia najlepszego rozwi±zania wystarczy przeszukiwanie lokalne. Polega ono na iteracyjnym sprawdzaniu rozwi±zañ w najbli¿szej przestrzeni i wprowadzaniu lokalnych zmian, aby w koñcu znale¼æ rozwi±zanie najlepsze w okolicy tzw. optimum lokalne. Je¶li wiemy, ¿e istnieje tylko jedno takie optimum, mo¿emy mieæ pewno¶æ, ¿e znalezione rozwi±zanie jest najlepszym w ca³ej przestrzeni rozwi±zañ. Przyk³adami optymalizacji lokalnych s±:
\begin{itemize}
\item hill climbing
\item przeszukiwanie tabu
\end{itemize}

Je¶li natomiast funkcja celu posiada wiele optimów lokalnych (tzw. funkcja wielomodalna) to optymalizacjê nazywamy optymalizacj± globaln±. Je¶li zadanie jest ci±g³e, a wiêc niemo¿liwe jest przeszukanie ca³ej przestrzeni rozwi±zañ, nigdy nie mo¿emy byæ pewni, ¿e zastosowany algorytm optymalizacji da nam rozwi±zanie najlepsze - byæ mo¿e bêdzie to tylko minimum lokalne a nie globalne. Nie maj±c takiej pewno¶ci nie wiemy kiedy nale¿y zatrzymaæ algorytm. Z tego powodu stosuje siê parametr steruj±cy czasem trwania obliczeñ, kosztem mniejszej pewno¶ci co do poprawno¶ci rozwi±zania mo¿emy otrzymaæ krótszy czas optymalizacji i odwrotnie.

\subsection{Algorytm ewolucyjny}
\label{sec:ewolucyjny}
Algorytm ewolucyjny jest przyk³adem algorytmu optymalizacyjnego, przeszukuj±cego przestrzeñ rozwi±zañ w celu znalezienia najlepszego rozwi±zania problemu. Algorytm ten oparty jest na obserwacjach ¶rodowiska i przystosowywania siê organizmów do jego warunków. Wiele terminów zapo¿yczonych jest zatem z genetyki.

Podstaw± ca³ego algorytmu jest populacja osobników, z których ka¿dy reprezentuje rozwi±zanie problemu. Populacja ta zmienia siê wraz z dzia³aniem algorytmu. Ewolucja zak³ada, ¿e populacja bêdzie siê sk³adaæ z coraz lepiej przystosowanych osobników. Przystosowanie to jest obliczane za pomoc± wcze¶niej okre¶lonej funkcji oceniaj±cej jako¶æ danego osobnika, czyli jak dobre jest rozwi±zanie reprezentowane przez niego. Przystosowanie jest warto¶ci± liczbow± obliczon± za pomoc± tej funkcji przystosowania.\\
Funkcja przystosowania okre¶la warto¶æ przystosowania osobnika na podstawie jego fenotypu, który jest tworzony z genotypu. Genotyp okre¶la zestaw cech danego osobnika i sk³ada siê z chromosomów (najczê¶ciej z jednego). Natomiast ka¿dy z chromosomów sk³ada siê z elementarnych jednostek - genów.\\

\subsubsection{Schemat dzia³a algorytmu ewolucyjnego}
Algorytm ewolucyjny rozpoczyna siê poprzez wygenerowanie populacji bazowej oraz obliczenie przystosowania jej osobników. Przewa¿nie osobniki te generowane s± ca³kowicie losowo, ale mo¿na tak¿e wprowadziæ konkretne osobniki np. o znanym dobrym przystosowaniu do ¶rodowiska.

G³ówna czê¶æ algorytmu opiera siê na powtarzaniu pêtli, w której wykonywane s± kolejno:

\begin{itemize}
\item reprodukcja
\item operacje genetyczne
\item ocena
\item sukcesja
\end{itemize}

Czêsto reprodukcjê i sukcesjê ³±czy siê pod nazw± selekcja.

Reprodukcja powoduje powielenie losowo wybranych osobników z populacji. Prawdopodobieñstwo wybrania osobnika do powielenia najczê¶ciej jest proporcjonalne do jego przystosowania. Mo¿e siê zdarzyæ, ¿e dany osobnik zostanie wybrany wiêcej ni¿ raz, a tak¿e, ¿e nie zostanie wybrany ani razu.\\
Nastêpnie na tych kopiach przeprowadzane s± operacje genetyczne powoduj±ce zmiany w genotypie osobników. Wyró¿niamy dwie podstawowe operacje:

\begin{itemize}
\item mutacja
\item krzy¿owanie
\end{itemize}

%---- WSTAWKA ANGIELSKA!!!!!!!!!!!!!!!!!--------
Zadaniem mutacji jest losowe zmodyfikowanie genów w genotypie.\\
Krzy¿owanie, zwane tak¿e rekombinacj± (ang. \textit{crossover}), dzia³a na conajmniej dwóch osobnikach i na podstawie ich genotypu tworzy jeden lub wiêcej osobników potomnych. Chromosomy rodzicielskie s± mieszane w celu otrzymania nowych genotypów dla osobników potomnych.

W wyniku operacji genetycznych powstaj± nowe osobniki, które wchodz± w sk³ad populacji potomnej. Ka¿dy z tych osobników jest oceniany za pomoc± funkcji przystosowania. Porównuj±c jako¶æ osobników z populacji bazowej oraz potomnej dokonuje siê sukcesji, czyli wyboru osobników z tych populacji (czasem wy³±cznie z populacji potomnej) i tworzy now± populacjê bazow±.

Zakoñczenie dzia³ania algorytmu przewa¿nie opiera siê na badaniu funkcji przystosowania ca³ej populacji. Je¶li warto¶æ przystosowania populacji nie jest zró¿nicowana mówimy o stagnacji algorytmu i mo¿e byæ to wskazaniem do zakoñczenia dzia³ania algorytmu. Czasem jednak oczekuje siê a¿ przystosowanie to bêdzie wystarczaj±co du¿e, ¿eby stwierdziæ, ¿e znalezione rozwi±zanie jest bardzo dobre. Przewa¿nie jednak nie znamy nawet przybli¿onej warto¶ci jako¶ci rozwi±zania, wiêc nie mo¿emy stwierdziæ kiedy przystosowanie jest odpowiednie i czy nie mo¿e siê jeszcze znacznie poprawiæ.

\subsubsection{Kodowanie osobników}
W przypadku algorytmów genetycznych, bêd±cych szczególnym przypadkiem algorytmów ewolucyjnych, do kodowania osobników stosuje siê kodowanie binarne chromosomów. Pojedynczy bit reprezentuje zatem gen nale¿±cy do chromosomu.\\
W takim przypadku mutacja wykonywana jest na ka¿dym genie osobno z pewnym prawdopodobieñstwem, je¶li do niej dochodzi, zmienia siê warto¶æ bitu na przeciwn±. W krzy¿owaniu wybiera siê dwa osobniki rodzicielskie, których chromosomy rozcinane s± na dwie czê¶ci i ³±czone "na krzy¿". Miejsce przeciêcia jest losowane z rozk³adem równomiernym.

W algorytmach ewolucyjnych porzuca siê kodowanie binarne - chromosom sk³ada siê z jednej lub wiêcej liczb stanowi±cych cechy osobnika.\\
Mutacja takiego osobnika najczê¶ciej odbywa siê poprzez losow± zmianê ka¿dej z warto¶ci genów chromosomu. Do krzy¿owania wybiera siê dwa osobniki, z których dla ka¿dej pary odpowiadaj±cych genów wyci±gana jest ¶rednia i tak otrzymane warto¶ci genów tworz± genotyp nowego osobnika.

\subsubsection{Typy algorytmów ewolucyjnych}
Algorytmy ewolucyjne wywodz± siê z kilku osobnych nurtów zajmuj±cych siê t± tematyk±, wiêc istnieje wiele podobnych schematów. Najlepiej traktowaæ algorytmy ewolucyjne jako metaheurystykê - okre¶lony jest pewien szkic algorytmu, który mo¿na dostosowywaæ do konkretnego rozwi±zania. W tym podrozdziale opisane s± podstawowe i najbardziej popularne schematy postêpowania oparte o algorytmy ewolucyjne.

\paragraph{Prosty algorytm genetyczny}

Prosty algorytm genetyczny zosta³ zaproponawny w roku 1975 przez John'a Holland'a.

Maj±c populacjê bazow± $P^t$ dokonujemy reprodukcji tej populacji, tworz±c populacjê tymczasow± $T^t$ sk³adaj±c± siê z takiej samej liczby osobników. Wybierani s± oni z prawdopodobieñstwem proporcjonalnym do ich przystosowania z populacji bazowej. Na populacji tymczasowej dokonujemy operacji genetycznych (mutacji i krzy¿owania). Do krzy¿owania wybierane s± roz³±czne pary osobników i z pewnym prawdopodobieñstwem $p_c$ zachodzi ich skrzy¿owanie. Je¶li dosz³o do powstania osobników potomnych zastêpuj± one osobniki rodzicielskie. Nastêpnie na tak otrzymanej populacji tymczasowej dochodzi do mutacji osobników i otrzymania populacji potomnej $O^t$. Ta populacja staje siê w nastêpnej iteracji algorytmu now± populacj± bazow±.\\
Zatrzymanie algorytmu mo¿e byæ dokonane je¶li np.:

\begin{itemize}
\item wykonano okre¶lon± z góry liczbê iteracji
\item znaleziono osobnika o wystarczaj±co wysokiej warto¶ci przystosowania
\end{itemize}

W tej wersji algorytmu czêsto pêtlê algorytmu nazywa siê generacj±, a ka¿d± populacjê $P^t$ w chwili t pokoleniem.\\

\paragraph{Strategia (1+1)}

Strategia (1+1) jest podstawow± strategii ewolucyjnych. W algorytmie tym mamy doczynienia z populacj± sk³adaj±c± siê z tylko jednego osobnika posiadaj±cego jeden chromosom. W ka¿dej pêtli algorytmu dokonuje siê mutacji tego chromosomu, co powoduje powstanie nowego osobnika. Osobnik ten jest poddawany ocenie, a nastêpnie dokonuje siê wyboru lepszego z dwóch istniej±cych osobników i tego pozostawia w populacji.\\
W mutacji dodaje siê do ka¿dego genu chromosomu losow± modyfikacjê rozk³adem normalnym:
\begin{equation}
Y^t_i = X^t_i + \sigma\xi_{N(0,1),i}
\end{equation}

Warto¶æ $\sigma$ bêdzie powodowa³a wiêksze lub mniejsze zmiany w chromosomie. Je¶li chcemy przeszukaæ przestrzeñ, powinni¶my zwiêkszaæ jej warto¶æ, co jest po¿±dane zw³aszcza w pocz±tkowej fazie dzia³ania agorytmu. Natomiast, aby znale¼æ jak najlepsze rozwi±zanie, wiedz±c ¿e obecne rozwi±zanie jest ju¿ bardzo bliskie najlepszemu, mo¿emy zmniejszaæ warto¶æ $\sigma$ przeszukuj±c tylko najbli¿sz± przestrzeñ.\\
Do wyznaczania $\sigma$ powsta³ nastêpuj±cy algorytm zwany regu³± 1/5 sukcesów:
\begin{enumerate}
\item Je¶li przez kolejnych k pêtli algorytmu mutacja powoduje powstanie lepszego osobnika w wiêcej ni¿ 1/5 wszystkich mutacji, to zwiêkszamy $\sigma$: $\sigma' = c_i \sigma$. Warto¶æ $c_i$ wyznaczona empirycznie wynosi $ \frac{1}{0.82} $
\item Gdy dok³adnie 1/5 koñczy siê sukcesem, warto¶æ $\sigma$ pozostaje bez zmian.
\item Je¶li nie zachodzi ¿adne z powy¿szych warto¶æ $\sigma$ jest zmniejszana: $\sigma' = c_d \sigma$. Gdzie $ c_d $ powinna wynosiæ $ 0.82 $
\end{enumerate}

\paragraph{Strategia ($\mu$ + $\lambda$)}

Strategia ($\mu$ + $\lambda$) jest rozwiniêciem strategii (1+1). $\mu$ oznacza ilo¶æ osobników w populacji pocz±tkowej, a $\lambda$ ile osobników jest reprodukowanych i poddawanych operacjom genetycznym. Dodatkowo, zamiast regu³y 1/5 sukcesów wprowadzono mechanizm samoczynnej adaptacji zasiêgu mutacji, a tak¿e wprowadzono operator krzy¿owania.

Oznaczenie $\mu$ + $\lambda$ oznacza, ¿e po wygenerowaniu populacji potomnej wybierane jest $\mu$ najlepszych osobników do nowej populacji bazowej - zarówno spo¶ród populacji potomnej, jak i starej populacji bazowej zawieraj±cej ³±cznie $\mu$ + $\lambda$ osobników.

W strategii tej wa¿ne jest te¿ kodowanie, do którego dodatkowo do³o¿ono równie¿ chromosom przechowuj±cy wektor $\sigma$ zawieraj±cy warto¶ci odchyleñ standardowych, które wykorzystuje siê w trakcie mutacji.\\
Po wylosowaniu warto¶ci zmiennej losowej o rozk³adzie normalnym ($\xi_{N(0,1)}$) dla ka¿dego elementu wektora $\sigma$ losujemy jeszcze jedn± zmienn± losow± o rozk³adzie normalnym ($\xi_{N(0,1),i}$) i oblicza nowe warto¶ci odchyleñ z wektora $\sigma$:

\begin{equation}
\sigma'_i = \sigma_i e^{(\tau'\xi_{N(0,1)} + \tau\xi_{N(0,1),i})}
\end{equation}

%--------CO Z K i n??-------
Gdzie $\tau$ oraz $\tau'$ s± parametrami algorytmu, a ich warto¶ci powinny wynosiæ:
\begin{equation}
\tau = \frac{K}{\sqrt{2n}}
\end{equation}

\begin{equation}
\tau' = \frac{K}{\sqrt{2\sqrt{n}}}
\end{equation}

Maj±c dane nowe warto¶ci odchyleñ standardowych mo¿emy obliczyæ nowe warto¶ci genów korzystaj±c ze wzoru:

\begin{equation}
X'_i = X_i + \sigma'_i\xi_{N(0,1),i}
\end{equation}
gdzie $\xi_{N(0,1),i}$ jest now± losow± warto¶ci±.

Algorytm ewolucyjny wybiera osobniki lepiej przystosowane, a wiêc te, które posiadaj± tak¿e lepsze warto¶ci odchyleñ standardowych. Powoduje to naturaln± selekcjê, doprowadzaj±c± do samoczynnej adaptacji odchyleñ standardowych stosowanych w trakcie mutacji.

Krzy¿owanie wystêpuje w tym algorytmie pod nazw± rekombinacja. Najczê¶ciej sprowadza siê do u¶rednienia lub wymianie warto¶ci wektorów, tak¿e wektora $\sigma$.

\paragraph{Strategia ($\mu$, $\lambda$)}
Strategia ($\mu$ + $\lambda$) posiada pewne wady, które postanowiono spróbowaæ wyeliminowaæ za pomoc± nowej strategii ($\mu$, $\lambda$). Poprzedni algorytm sprawia problemy je¶li w populacji pojawia siê osobnik o wysokiej warto¶ci przystosowania, ale posiadaj±cy zbyt du¿e (albo zbyt ma³e) warto¶ci odchyleñ standardowych. Usuniêcie takiego osobnika z populacji czêsto nie jest procesem krótkotrwa³ym, gdy¿ wp³ywa on na powstaj±ce potomstwo, przekazuj±c mu podobne do jego, nieodpowiednie warto¶ci odchyleñ.\\
W nowej strategii wprowadzono zmianê, która powoduje, ¿e osobniki rodzicielskie nie s± nigdy brane do kolejnej populacji bazowej. Podczas selekcji korzysta siê zatem tylko z powsta³ej populacji potomnej, z niej wybieraj±c osobniki do populacji bazowej w kolejnej iteracji.

\subsection{Hill climbing}
\label{sec:hill}
Algorytm hill climbing jest jedn± z metod przeszukiwania lokalnego. W ka¿dej iteracji zmieniaj±c warto¶æ jednej ze zmiennych rozwi±zania sprawdzana jest warto¶æ funkcji celu dla nowego rozwi±zania i je¶li warto¶æ ta jest lepsza od dotychczas najlepszej znalezionej, zapamiêtujemy zmienione rozwi±zanie. Dopóki zmiany powoduj± poprawê rozwi±zania, algorytm nie jest zatrzymywany. Na koñcu wiemy, ¿e znalezione rozwi±zanie jest rozwi±zaniem lokalnie optymalnym.\\
Przeszukiwanie przestrzeni dyskretnej sprowadza siê do sprawdzenia rozwi±zañ najbli¿szych obecnemu i wybieranie tego rozwi±zania, którego warto¶æ obliczona za pomoc± funkcji celu jest najlepsza. Je¶li w¶ród s±siadów nie ma ju¿ lepszego rozwi±zania, mo¿emy zakoñczyæ przeszukiwanie.\\
W przestrzeni ci±g³ej konieczne jest dobranie kroku, który wyznacza punkty przeszukiwane w okolicy w trakcie ka¿dej iteracji. Dodatkowo wykorzystywane jest tzw. przyspieszenie (ang. \textit{acceleration}), które wyznacza piêciu mo¿liwych kandydatów na lepsze rozwi±zania. Najczê¶ciej przyspieszenie to wynosi 1.2, a warto¶æ kroku jest osobna dla ka¿dej zmiennej rozwi±zania i czêsto wynosi na pocz±tku 1. Zatem za ka¿dym razem obliczane s± nastêpuj±ce wspó³czynniki: -acceleration, -1/acceleration, 0, 1/acceleration, acceleration. Nastêpnie wspó³czynniki mno¿one s± przez krok (step) i dodawane do obecnie analizowanej zmiennej i wybierane jest najlepsze z piêciu rozwi±zañ. Warto¶æ kroku jest indywidualna dla ka¿dej zmiennej. Po wybraniu najlepszego rozwi±zania uaktualniana jest warto¶æ tego kroku - krok mno¿ony jest przez odpowiedni wspó³czynnik, ten który by³ dobrany wcze¶niej do znalezienia tego najlepszego rozwi±zania. Algorytm zatrzymywany jest je¶li zmiana ¿adnej ze zmiennych nie przynosi ju¿ poprawy rozwi±zania, czasem równie¿ je¶li ta zmiana jest ju¿ bardzo ma³a - wprowadzany jest parametr $\epsilon$ wyznaczaj±cy tê ró¿nicê.

%---------------------------------------------------------------------------

\section{Uczenie maszynowe}
\label{sec:maszynowe}

Uczeniem siê systemu jest ka¿da autonomiczna zmiana w systemie zachodz±ca na podstawie do¶wiadczeñ, która prowadzi do poprawy jako¶ci jego dzia³ania. (Cichosz)

Program siê uczy z do¶wiadczenia E dla zadañ T i miary jako¶ci P je¶li jego efektywno¶æ w zadaniach z T mierzona P wzrasta z do¶wiadczeniem E. (Mitchell)

Istnieje wiele rodzajów uczenia maszynowego. Podstawowy podzia³ wynika z rodzaju informacji trenuj±cej na:

\begin{itemize}
\item uczenie z nadzorem
\item uczenie bez nadzoru
\end{itemize}

W uczeniu siê z nadzorem ¼ród³em informacji trenuj±cej jest nauczyciel. Od niego otrzymuje uczeñ informacjê jakie zachowanie jest po¿±dane. Natomiast w przypadku uczenia bez nadzoru uczeñ dowiaduje siê o skuteczno¶ci swojego dzia³ania obserwuj±c wyniki - nazywa siê to czasem wbudowanym nauczycielem.

Istniej± jeszcze dwie grupy, które trudno zakwalifikowaæ do powy¿szych:

\begin{itemize}
\item uczenie siê na podstawie zapytañ
\item uczenie siê przez eksperymentowanie
\item uczenie siê ze wzmocnieniem
\end{itemize}

Do pierwszej z nich nale¿± algorytmy polegaj±ce na zadawaniu pytañ przez ucznia nauczycielowi. Natomiast do drugiej te, w których uczeñ gromadzi swoje do¶wiadczenia obserwuj±c konsekwencje swojego dzia³ania w ¶rodowisku. Uczenie siê ze wzmocnieniem jest podobne do tej metody, ale dodatkowo istnieje krytyk, który s³u¿y jako dodatkowe ¼ród³o informacji trenuj±cej. Jego zadaniem jest karanie b±d¼ nagradzanie ucznia za jego zachowanie. Uczeñ nie dowiaduje siê co ma robiæ, ale jak warto¶ciowe jest dane dzia³anie.

Czasem granice pomiêdzy tymi grupami s± nieostre i przynale¿no¶æ algorytmu do jakiej¶ grupy mo¿e zale¿eæ wy³±cznie od punktu widzenia.

\subsection{Uczenie siê ze wzmocnieniem}
W przypadku uczenia siê ze wzmocnieniem zadaniem ucznia jest obserwacja stanów ¶rodowiska, wykonywanie akcji oraz obserwowanie efektów tych akcji poprzez warto¶æ otrzymywanego wzmocnienia jako rzeczywistoliczbowej nagrody. Tak jak zosta³o to napisane wcze¶niej, w tym przypadku nie mówimy o nauczycielu, ale o krytyku, który warto¶ciuje zachowanie poprzez dostarczanie wzmocnienia. Zadaniem ucznie jest odnalezienie takiego zachowania, które przyniesie mu jak najwiêksz± nagrodê. Najczê¶ciej uczeñ nie ma pojêcia o tym jakie jest ¶rodowisko, czêsto niedeterministyczne, dlatego musi wchodziæ w interakcjê z nim, aby je poznaæ.

\begin{figure}[h]
\centering
\includegraphics{uczenie}
\end{figure}

W ka¿dym kroku uczeñ jest w okre¶lonym stanie ¶rodowiska. Decyduj±c siê na okre¶lon± akcjê otrzymuje informacjê o nowym stanie, w którym znajduje siê po wykonaniu tej akcji oraz o nagrodzie (wzmocnieniu) jak± otrzymuje za swoje dzia³anie. Uczeñ obserwuj±c nagrody otrzymywane za swoje zachowanie mo¿e uczyæ siê jak postêpowaæ, aby by³y one jak najwy¿sze.

Schemat algorytmu przedstawia siê nastêpuj±co:\\
Dla kolejnych kroków czasowych t: 
\begin{enumerate}
\item obserwujemy stan $x_t$
\item wybieramy akcjê $a_t$ mo¿liw± do wykonania w stanie $x_t$
\item wykonujemy akcjê $a_t$
\item obserwujemy wzmocnienie $r_t$ i nastêpny stan $x_{t+1}$
\item uczymy siê na podstawie do¶wiadczenia ($x_t,a_t,r_t,x_{t+1}$)
\end{enumerate}
Wybór akcji w kroku 2. dokonywany jest autonomicznie przez ucznia. Natomiast stan, do którego przechodzi po wykonaniu akcji jest okre¶lony przez ¶rodowisko na podstawie stanu poprzedniego oraz wykonanej akcji. Warto jednak zwróciæ uwagê na fakt, ¿e ¶rodowisko mo¿e byæ stochastyczne - wykonanie dwa razy tej samej akcji mo¿e dawaæ ró¿ne rezultaty. Poza tym, przewa¿nie ¶rodowisko jest nieznane uczniowi, st±d konieczno¶æ podejmowania prób i b³êdów poprzez wykonywanie ró¿nych akcji. Jednocze¶nie, uczeñ nie mo¿e wp³ywaæ na ¶rodowisko w ¿aden sposób.

\subsubsection{Strategia maksymalizacji nagród}
Nauka ucznia oparta jest na nagrodach, które otrzymuje za swoje dzia³ania. Musi znale¼æ on najlepsz± strategiê wyboru akcji, aby uzyskiwaæ jak najlepsze nagrody. Najczê¶ciej uczeñ próbuje maksymalizowaæ swoje nagrody d³ugoterminowo. Strategia ta polega na tym, ¿e nagrody za poprawne dzia³anie mog± przyj¶æ wiele kroków pó¼niej ni¿ wtedy gdy ono zosta³o wykonane. Strategia ta nazywana jest uczeniem siê z opó¼nionym wzmocnieniem. W uczeniu z natychmiastowym wzmocnieniem interesuje nas tylko maksymalizacja nagród tu¿ po danym zachowaniu. Nie jeste¶my wtedy w stanie braæ pod uwagê tego, jakie w przysz³o¶ci mog± byæ jego skutki.\\
W przypadku opó¼nionego wzmocnienia wprowadza siê wspó³czynnik dyskontowania $\gamma \in [0,1]$. Zadaniem ucznia jest zmaksymalizowanie zdyskontowanej sumy nagród:

\begin{equation}
E[\sum_{t=0}^\infty \gamma^tr_t]
\end{equation}

Im wspó³czynnik $\gamma$ jest bli¿szy 0, tym bardziej maksymalizuje siê tylko natychmiastowe nagrody. Je¶li $\gamma = 1$ to maksymalizowana jest suma wszystkich otrzymanych nagród.

\subsubsection{Zadania epizodyczne}

\section{Volunteer Computing}
\label{volunteerComputing}

Volunteer computing to nieformalny kontrakt w którym zwykli ludzie czy te¿ organizacje, nazywani dalej ochotnikami, dobrowolnie udostêpniaj± swoje zasoby obliczeniowe by uruchamiaæ na nich obliczenia zwi±zane z ró¿norakimi projektami. Projekty to, przewa¿nie projekty naukowe, których celem jest rozwi±zanie problemów i zadañ matematycznych czy te¿ problemów dotykaj±cych ludzko¶æ, lub d±¿±cych do lepszego poznania ¶wiata i wszech¶wiata. Dziêki platform± umo¿liwiaj±cym Volunteer computing, ka¿dy cz³owiek mo¿e w niewielkim stopniu kontrybuowaæ w rozwi±zywaniu tych problemów.

Ochotnicy to osoby prywatne albo instytucje takie jak szko³y czy uniwersytety. Ochotnicy przewa¿nie pozostaj± anonimowi, choæ w niektórych projektach wymagane jest dostarczenie podstawowych danych kontaktowych jak np. adresu email. W wypadku celowego dostarczania b³êdnych wyników przez ochotnika, utrudnione jest jego dyscyplinowanie czy te¿ wy³±czenie z projektu. Ochotnicy nie s± wynagradzani finansowo za uczestnictwo w projekcie. 

Organizacja czy osoba chc±ca wykorzystaæ model Volunteer computing do swoich projektów, musi byæ jednostk± zaufan± dla ochotników realizuj±cych obliczenia. Wynika to z prostego faktu, ¿e ochotnicy decyduj± siê, wed³ug standardowego modelu computing,  na zainstalowanie aplikacji dostarczanej przez dawcê zadañ obliczeniowych. Osoba instaluj±ca aplikacjê musi ufaæ, ¿e nie uszkodzi ona jej komputera ani te¿ nie bêdzie wykorzystywaæ jej zasobów w sposób niezgodny z zapewnieniami zleceniodawcy obliczeñ. Zleceniobiorca obliczeñ ma te¿ prawo oczekiwaæ, ¿e aplikacja, zosta³a napisana przestrzegaj±c dobrych praktyk bezpieczeñstwa, gdy¿ jako, ¿e aplikacja ta ³±czy siê z internetem i potencjalnie jest zainstalowana na du¿ej ilo¶ci maszyn wiêc jest atrakcyjnym celem ataków zmierzaj±cych do przejêcia  tych maszyn do niezgodnych z prawem celów przez hakerów. 

Przewa¿nie model komunikacyjny systemu Volunteer Computing uwzglêdnia tylko komunikacje poszczególnych klientów z centralnym serwerem i nie zak³ada bezpo¶redniej komunikacji miêdzy klientami.

Volunteer Computing pierwotnie zak³ada³, ¿e obliczenia s± wykonywane na zwyk³ych PC-tach. Ilo¶æ komputerów tego typu jest nieporównywalnie wiêksza do ilo¶ci wyspecjalizowanych komputerów o du¿ej mocy obliczeniowej i jest szacowana na ponad miliard. Dodatkowa, z przyczyn ekonomicznych, na rozwój tych maszyn producenci sprzêtu przeznaczaj± najwiêksze fundusze wiêc ich moc i zdolno¶ci obliczeniowe stale rosn±. 

Wa¿nym aspektem, który istotnie wp³ywa na stosowanie modelu w praktyce jest koszt prowadzenia obliczeñ. Model zak³ada, ¿e do³±czanie siê do obliczeñ jest ochotnicze i nie dostaje siê za uczestnictwo w projekcie wynagrodzenia. Dziêki temu, projekty, które maj± poparcie i akceptacjê spo³eczn± mog± liczyæ na darmowe moce obliczeniowe udostêpnione przez zwyk³ych ludzi.

Na ten model mo¿na patrzyæ tak¿e w kategoriach edukacyjnych. Podczas gdy ochotnik przystêpuje do projektu i udostêpnia swoje moce obliczeniowe, mo¿na wykorzystaæ jego potencjalne zainteresowanie rozwi±zywanym problemem i za pomoc± przystêpnych wizualizacji przedstawiæ mu sedno rozwi±zywanego zadania, nakre¶liæ mu problem z ró¿nych perspektyw i pokazaæ mu do czego potencjalnie zmierzaj± obliczenia. Po³±czenie atrakcyjnej formy t³umaczenia rozwi±zywanych problemów z potencja³em portali spo³eczno¶ciowych i wiralno¶ci ciekawego materia³u mo¿na uzyskaæ daleko id±cy efekt propagacji i pod³±czaniu siê do obliczeñ coraz wiêkszej ilo¶ci osób.

\section{Web Workers}
\label{webWorkers}

Przeprowadzanie intensywnych obliczeñ w przegl±darkach internetowych nie by³o mo¿liwe do czasu wprowadzenia przez  grupê WHATWG (Web Hypertext Application Technology Working Group) specyfikacji Web Worker. Ograniczenie wynika³o z faktu, ¿e jêzyk w którym wykonywane s± skrypty poprzez silniki przegl±darki to Java Script. Java Script to ¶rodowisko jednow±tkowe, wiêc nic nie mo¿e byæ wykonywane równolegle. Zlecaj±c wiêc skryptowi intensywne obliczenia, na ich czas ca³y UI strony by³by nieresponsywny, co jest nie do przyjêcia dla cz³owieka obs³uguj±cego stronê internetow±. Przegl±darki broni± u¿ytkownika przed takim zachowaniem skryptów na stronie i czasami zdarza siê jeszcze zobaczyæ okno z ostrze¿eniem, ¿e skrypt przesta³ odpowiadaæ i mo¿liwo¶ci± manualnego zatrzymania skryptu.

Web Workers definiuje API do tworzenia osobnych procesów w tle. Workery wykorzystuj± do komunikacji z w±tkiem g³ównym klasyczny model przekazywania wiadomo¶ci. Nowoczesne przegl±darki umo¿liwiaj± przekazywanie zarówno tekstu jak i obiektów zserializowanych jako JSONy. Nale¿y zwróciæ uwagê, ¿e obiekty te nie s± wspó³dzielone ale w pe³ni kopiowane. 

Web Workery nie ma j± dostêpu do struktury DOM, obiektu \textit{window} ani \textit{document}. Zewnêtrzne skrypty wykorzystywane przez workera musz± byæ serwowane z tej samej domeny co kod workera.

Wed³ug specyfikacji, stworzonej przez WHATWG, Web Workery powinny byæ u¿ywane do zadañ trwaj±cych d³u¿szy czas, maj±cych du¿y narzut startowy i spory narzut pamiêciowy. Nie s± wiêc odpowiednie tworzenie bardzo wielu workerów zajmuj±cych siê obliczeniami trwaj±cymi marginalny czas, gdy¿ sam narzut na stworzenie przez przegl±darkê osobnego procesu mo¿e byæ zbyt du¿y by uzasadniæ jego u¿ycie.
