\chapter{Wprowadzenie teoretyczne i istniej±ce rozwi±zania - Optymalizacja}
\label{cha:wstepTeoretyczny}

Zrozumienie istoty przedstawionego w tej pracy rozwi±zania doboru optymalnej trasy narciarza, zarówno pod wzglêdem algorytmicznym jak i architektonicznym, wymaga zaznajomienia siê z istotnymi pojêciami. W tym rozdziale, przedstawimy i opiszemy te pojêcia.

\section{Jazda po zadanym torze w narciarstwie alpejskim}
\label{sec:alpineSkiing}

Sportowa jazda na nartach zjazdowych podzielona jest na kilka dyscyplin. S± to: slalom (SL), slalom gigant (GS), super gigant (GS) oraz zjazd (DH). Elementem wspólnym ka¿dej z nich jest konieczno¶æ pokonania trasy, od startu do mety, w jak najkrótszym czasie i przy prawid³owym przejechaniu ka¿dej z bramek znajduj±cych siê na trasie przejazdu. Szczegó³owe zasady dotycz±ce parametrów stoku i sprzêtu okre¶la regulamin organizacji FIS (Federation International du Ski), z po¶ród których najbardziej istotnymi s±:

\begin{itemize}
\item minimalna i maksymalna ró¿nica wzniesieñ na trasie
\item minimalna i maksymalna odleg³o¶æ pomiêdzy kolejnymi bramkami
\item liczba bramek jaka powinna siê znale¼æ na trasie - proporcjonalnie do ró¿nicy wzniesieñ
\item minimalna d³ugo¶æ narty
\item minimalny promieñ skrêtu narty
\end{itemize}

Parametry te ró¿ni± siê w zale¿no¶ci od dyscypliny. Najbardziej techniczn± dyscyplin± jest slalom, nazywany wcze¶niej slalomem specjalnym. Wyró¿nikiem tej dyscypliny jest du¿a liczba bramek znajduj±cych siê w niewielkiej odleg³o¶ci od siebie. Gêste ustawienie bramek wymusza czêste skrêty, bardzo liczy siê zatem technika i zwinno¶æ narciarza.  Zawodnicy je¿d¿± slalom na nartach o bardzo ma³ym promieniu skrêtu, rzêdu 11 metrów. Bramka w slalomie sk³ada siê z dwóch tyczek tego samego koloru. W slalomie gigancie, odleg³o¶ci miêdzy kolejnymi bramkami s± wiêksze, co implikuje szybsz± jazdê. Bramka w tej dyscyplinie sk³ada siê z czterech tyczek tego samego koloru, po dwie na ka¿dy koniec bramki. Dodatkowo ka¿de dwie tyczki z koñca bramki po³±czone s± p³acht± tego samego koloru co tyczki - czerwon± lub niebiesk±. Zawodnicy do tej dyscypliny u¿ywaj± nart o promieniu nawet 35 metrów. Kolejne dyscypliny s± jeszcze szybsze a promienie nart coraz wiêksze. Bramki zarówno w super gigancie jak i zje¼dzie, s± analogiczne do tych gigantowych, ró¿ni± siê tylko szeroko¶ci± p³acht. Super gigant to konkurencja podobna do slalomu giganta, z tym, ¿e odleg³o¶ci miêdzy bramkami s± bardzo du¿e, a zatem zawodnicy uzyskuj± podczas przejazdu du¿o wiêksze prêdko¶ci. Zjazd to ju¿ typowa dyscyplina szybko¶ciowa. Na trasie zakrêty wynikaj± prawie tylko z konfiguracji terenu. Dodatkowo zdarzaj± siê na trasie elementy ukszta³towania terenu na których zawodnicy wybijaj± siê i skacz± po nawet 80 metrów.

Aby poprawnie przejechaæ przez bramkê na trasie, w ka¿dej z opisywanych wy¿ej dyscyplin, nale¿y przejechaæ pomiêdzy tyczkami wyznaczaj±cymi tzw. \textit{¶wiat³o bramki}. Bramki wymuszaj± skrêty, ale nie jest tak, ¿e ustawione s± zawsze rytmicznie tzn. wymuszaj±c skrêty raz w praw±, raz w lew± stronê o tym samym promieniu. Najczê¶ciej spotykanym rodzajem bramki jest tzw. \textit{bramka otwarta}. Bramka otwarta charakteryzuje siê tym, ¿e ¶wiat³o bramki znajduje siê prostopadle do linii spadku stoku. Poza bramkami otwartymi, bramki mog± byæ ustawione w tzw. figury slalomowe. Pierwsz± z nich jest \textit{przelot} i mo¿e wystêpowaæ w ka¿dej z dyscyplin. Przelot polega na ustawieniu dwóch kolejnych bramek w taki sposób, by nie wymuszaæ skrêtu pomiêdzy nimi. Przelot stosowany jest w celu lepszego dostosowania ustawienia trasy przejazdu do konfiguracji terenu, np. gdy na trasie naturalnie wystêpuje d³u¿szy skrêt w jedn± ze stron lub aby daæ zawodnikowi mo¿liwo¶æ rozpêdzenia siê. Kolejn± figur±, stosowan± ju¿ tylko w slalomie, jest \textit{³okieæ}. £okieæ to dwie bramki ustawione w bliskiej odleg³o¶ci jedna pod drug± w linii spadku stoku. S± to bramki zamkniête, czyli takie, w których ¶wiat³o bramki jest równoleg³e do linii spadku stoku. Figura ta wprowadza zmianê rytmu i równie¿ pozwala na dostosowanie trasy do konfiguracji terenu. Ostatni± z figur, równie¿ stosowan± tylko w slalomie, jest \textit{wertikal}. Wertikal to bramki ustawione tak samo jak w przypadku ³okcia, czyli jedna pod drug±, w linii spadku stoku, z tym, ¿e zamiast dwóch, mog± to byæ trzy, cztery czy nawet piêæ kolejno tak ustawianych bramek.

Podczas ogl±dania trasy, przed zawodami czy te¿ podczas treningów, zawodnicy zwracaj± du¿± uwagê na zapamiêtanie wystêpuj±cych po sobie figur i przewidywanie, na podstawie do¶wiadczenia, w jaki sposób nale¿y najechaæ na dan± figurê, by zmie¶ciæ siê, czy te¿ najszybciej pokonaæ kolejne, nastêpuj±ce po danej figurze bramki. Poprzez najazd na figurê, rozumiemy moment rozpoczêcia i sposób prowadzenia skrêtu przed figur±. Im wcze¶niej narciarz zrobi najazd, tym szybciej, po poprawnym przejechaniu bramki, bêdzie móg³ zmieniæ kierunek jazdy do kolejnych tyczek. Czasem warto skrêt rozpocz±æ wcze¶niej, tak by zmie¶ciæ siê w kolejnej podkrêconej bramce, czasem z kolei bardziej optymalne jest rozpêdzenie siê i rozpoczêcie skrêtu z opó¼nieniem, je¶li tylko dalsza konfiguracja slalomu pozwoli na zmieszczenie siê w kolejnych bramkach, mimo posiadania znacznej prêdko¶ci.

%---------------------------------------------------------------------------

\section{Fizyczny model narciarza}
\label{sec:fizycznyModel}

Aby dobrze odwzorowaæ jazdê narciarza po slalomie, nale¿y uwzglêdniæ wszystkie zachodz±ce w jego ¶rodowisku zjawiska fizyczne. W tym rozdziale pokazane zostanie w jaki sposób jest mo¿liwe zamodelowanie narciarza, stoku oraz trasu po którym siê porusza.

\subsubsection{Si³a oporu powietrza}
\label{sec:oporPowietrza}
Si³a oporu powietrza jest przyk³adem si³y tarcia p³ynu. Zale¿no¶æ warto¶ci tej si³y od prêdko¶ci mo¿e byæ bardzo z³o¿ona. Tylko w specjalnych przypadkach równanie opisuj±ce si³ê oporu powietrza mo¿e byæ rozwi±zana analitycznie. Si³a oporu powietrza jest w dobrym przybli¿eniu proporcjonalna do kwadratu prêdko¶ci poruszaj±cego siê obiektu i zale¿no¶æ t±, mo¿na opisaæ równaniem:


\begin{equation}
F_d = \frac{1}{2}C\rho Av^2
\end{equation}

C - wspó³czynnik oporu powietrza, typowe warto¶ci oscyluj± miêdzy 0.4 a 1. Warto¶æ wspó³czynnika zale¿y miêdzy innymi od kszta³tu obiektu i mo¿na go wi±zaæ z tzw. ,,op³ywowo¶ci±'' obiektu

$\rho$ - gêsto¶æ powietrza w jednostce $\frac{kg}{m^3}$. Warto¶ci gêsto¶ci powietrza przy przeciêtnym ci¶nieniu wahaj± siê miêdzy 1.26 a 1.42 w zale¿no¶ci od temperatury.

A - frontalna powierzchnia narciarza w projekcji prostopad³ej do wektora prêdko¶ci narciarza wyra¿ona w $m^{2}$.

\begin{figure}[h]
\label{fig:airDrag}
\caption{Warto¶æ wspó³czynnika $A$ w zale¿no¶ci od pozycji narciarza. Grafika pochodzi z badañ prowadzonych w tunelu aerodynamicznym IAT we Francji, opisanych przez Caroline Barelle z National Technical University of Athens z Grecji. \cite{AirDrag}}
\centering
\includegraphics{airDrag}
\end{figure}

Pozycja narciarza ma znacz±cy wp³yw na warto¶æ wspó³czynnika $A$, co widaæ na rysunku \ref{fig:airDrag} na stronie \pageref{fig:airDrag}. Przyjêcie pozycji zjazdowej redukuje w stosunku do pozycji podniesionej, warto¶æ wspó³czynnika nawet o jedn± trzeci±. Warto nadmieniæ równie¿, ¿e narciarze, nawet na amatorskich zawodach ubrani s± w specjalne kombinezony tzw. \textit{gumy narciarskie}. Kombinezony te s± jednoczê¶ciowe i ¶ci¶le przylegaj± do cia³a. Nie posiadaj± ¿adnych odstaj±cych elementów, czasami zawieraj± tylko wewnêtrzne ochraniacze w miejscach w których narciarz uderza przy ka¿dym skrêcie cia³em w tyczkê. Powodem dla którego strój ten jest tak popularny równie¿ w amatorskim sporcie jest fakt, ¿e znacz±co zmniejsza opór powietrza, w stosunku do klasycznego stroju narciarskiego i potrafi na kilkudziesiêciu sekundowej trasie, gdzie liczy siê ka¿da setna sekundy, redukowaæ czas przejazdu nawet o kilkadziesi±t setnych sekundy.

\subsubsection{Interakcje miedzy ¶niegiem a nartami}
\label{sec:interakcje}
To, ¿e narty ¶lizgaj± siê na ¶niegu zawdziêczamy skomplikowanym oddzia³ywaniom miêdzy powierzchni± narty a ¶niegiem czy lodem. Liczba czynników jakie wp³ywaj± na t± interakcjê jest bardzo du¿a, a z po¶ród nich warto wymieniæ:

\begin{itemize}
\item materia³ wykonania ¶lizgu narty
\item rodzaj, jako¶æ, sposób nak³adania i kolejno¶æ nak³adania smarów na ¶lizg narty
\item g³adko¶æ ¶lizgu narty
\item rodzaj i pochodzenie ¶niegu (naturalne/sztuczne)
\item temperatura i stopieñ zanieczyszczenia ¶niegu
\item warto¶æ k±ta nachylenia miêdzy powierzchni± ¶lizgu a pod³o¿em
\end{itemize}


Jest jeszcze jeden czynnik wp³ywaj±cy na tê interakcjê, tzw. \textit{water suction} (w wolnym t³umaczeniu zasysanie wody). W temperaturze powy¿ej -3 stopni Celsjusza, ciep³o powstaj±ce na skutek tarcia, topi cienk± warstwê ¶niegu pod nartami. Aby zredukowaæ ten negatywnie wp³ywaj±cy na po¶lizg efekt, ¶lizg narty ma perforowan± strukturê, któr± nale¿y zachowywaæ i odkrywaæ po ka¿dym smarowaniu, aby odprowadzaæ wodê. 

Wed³ug badañ przeprowadzonych przez Chris'a Talbot'a z European Space Agency \cite{Skiwaxes}, tarcie o ¶nieg ma du¿o wiêkszy wp³yw na czas przejazdu ni¿ si³y oporu powietrza.

\subsubsection{Tarcie kinetyczne}
\label{sec:tarcieKinetyczne}
Tarcie kinetyczne ma du¿o wiêksze znaczenie ni¿ tarcie statyczne poniewa¿ determinuje jak du¿a si³a musi dzia³aæ, ¿eby zachowaæ po¿±dan± prêdko¶æ podczas zjazdu. Wspó³czynnik tarcia kinetycznego miêdzy ¶niegiem a nasmarowanymi nartami wynosi ¶rednio 0.05 \cite{Skiwaxes}. Wspó³czynnik ten jednak mo¿e siê znacz±co zmieniaæ i w zale¿no¶ci od rodzaju smarów, sposobu smarowania oraz jako¶ci ¶niegu wynosi miêdzy 0.001 a 0.3 \cite{Skiwaxes}. Ju¿ na amatorskich zawodach, mo¿na zaobserwowaæ staranne przygotowanie ¶lizgów przed ka¿dym zjazdem i u¿ywanie smarów, których cena wynosi nawet kilkaset z³otych, a które s± zu¿ywane w ci±gu jednego sezonu startów. 

%---------------------------------------------------------------------------

\section{Optymalizacja}
\label{sec:optymalizacja}

W tym podrozdziale opisane s± metody optymalizacji u¿yte w zaproponowanym rozwi±zaniu, czyli algorytm ewolucyjny oraz algorytm optymalizacji lokalnej - Hill climbing.

Zadaniem optymalizacji jest przeszukanie przestrzeni rozwi±zañ w celu znalezienia najlepszego. Zatem, dana jest funkcja, nazywan± funkcj± celu, która ka¿demu punktowi reprezentuj±cemu rozwi±zanie problemu przypisuje jak±¶ warto¶æ oceniaj±c± jego jako¶æ. W¶ród wszystkich rozwi±zañ poszukujemy takiego, dla którego warto¶æ tej funkcji bêdzie jak najmniejsza (b±d¼ jak najwiêksza) - najlepsza z naszego punktu widzenia. Trudno¶æ w znalezieniu takiego rozwi±zania zale¿y od charakteru funkcji celu, a czasem tak¿e od nieznajomo¶ci jej analitycznej postaci.

\subsection{Optymalizacja lokalna i globalna}
W przypadku funkcji z jednym optimum do znalezienia najlepszego rozwi±zania wystarczy przeszukiwanie lokalne. Polega ono na iteracyjnym sprawdzaniu rozwi±zañ w najbli¿szej przestrzeni i wprowadzaniu lokalnych zmian, aby w koñcu znale¼æ rozwi±zanie najlepsze w okolicy tzw. optimum lokalne. Je¶li wiemy, ¿e istnieje tylko jedno takie optimum, mo¿emy mieæ pewno¶æ, ¿e znalezione rozwi±zanie jest najlepszym w ca³ej przestrzeni rozwi±zañ. Przyk³adami optymalizacji lokalnych s±:
\begin{itemize}
\item hill climbing
\item przeszukiwanie tabu
\end{itemize}

Je¶li natomiast funkcja celu posiada wiele optimów lokalnych (tzw. funkcja wielomodalna) to optymalizacjê nazywamy optymalizacj± globaln±. Je¶li zadanie jest ci±g³e, a wiêc niemo¿liwe jest przeszukanie ca³ej przestrzeni rozwi±zañ, nigdy nie mo¿emy byæ pewni, ¿e zastosowany algorytm optymalizacji da nam rozwi±zanie najlepsze - byæ mo¿e bêdzie to tylko minimum lokalne, a nie globalne. Nie maj±c takiej pewno¶ci nie wiemy kiedy nale¿y zatrzymaæ algorytm. Z tego powodu stosuje siê parametr steruj±cy czasem trwania obliczeñ - kosztem mniejszej pewno¶ci co do poprawno¶ci rozwi±zania mo¿emy otrzymaæ krótszy czas optymalizacji i odwrotnie.

\subsection{Algorytm ewolucyjny}
\label{sec:ewolucyjny}
Algorytm ewolucyjny jest przyk³adem algorytmu optymalizacyjnego, przeszukuj±cego przestrzeñ rozwi±zañ w celu znalezienia najlepszego rozwi±zania problemu. Algorytm ten bazuje jest na obserwacjach ¶rodowiska i przystosowywania siê organizmów do jego warunków. Wiele terminów zapo¿yczonych jest zatem z genetyki.

``Algorytm ewolucyjny przetwarza populacjê osobników, z których ka¿dy jest propozycj± rozwi±zania postawionego problemu. Dzia³a on w ¶rodowisku, które mo¿na zdefiniowaæ na podstawie problemu rozwi±zywanego przez algorytm. W ¶rodowisku ka¿demu osobnikowi jest przyporz±dkowana warto¶æ liczbowa, okre¶laj±ca jako¶æ reprezentowanego przez niego rozwi±zania; warto¶æ ta jest nazywana przystosowaniem osobnika.'' \cite{arabas}

Funkcja przystosowania okre¶la warto¶æ przystosowania osobnika na podstawie jego fenotypu, który jest tworzony z genotypu. Genotyp okre¶la zestaw cech danego osobnika i sk³ada siê z chromosomów (najczê¶ciej z jednego). Natomiast ka¿dy z chromosomów sk³ada siê z elementarnych jednostek - genów.\\

\subsubsection{Schemat dzia³ania algorytmu ewolucyjnego}
Na pocz±tku algorytmu ewolucyjnego generowana jest populacja bazowa oraz obliczane przystosowanie ka¿dego z jej osobników. Przewa¿nie osobniki te generowane s± ca³kowicie losowo, ale mo¿na tak¿e wprowadziæ konkretne osobniki np. o znanym dobrym przystosowaniu do ¶rodowiska.

G³ówna czê¶æ algorytmu opiera siê na powtarzaniu pêtli, w której wykonywane s± kolejne kroki przedstawione w \ref{alg:glowny}.

\begin{algorithm}
\caption{Schemat dzia³ania algorytmu ewolucyjnego}
\label{alg:glowny}
\begin{algorithmic}
\STATE	$reprodukcja$
\STATE	$operacje$ $genetyczne$
\STATE	$ocena$
\STATE	$sukcesja$
\end{algorithmic}
\end{algorithm}


Czêsto reprodukcjê i sukcesjê ³±czy siê pod nazw± selekcja.

Reprodukcja powoduje powielenie losowo wybranych osobników z populacji. Prawdopodobieñstwo wybrania osobnika do powielenia najczê¶ciej jest proporcjonalne do jego przystosowania. Mo¿e siê zdarzyæ, ¿e dany osobnik zostanie wybrany wiêcej ni¿ raz, a tak¿e, ¿e nie zostanie wybrany ani razu.\\
Nastêpnie na tych kopiach przeprowadzane s± operacje genetyczne powoduj±ce zmiany w genotypie osobników. Wyró¿niamy dwie podstawowe operacje:

\begin{itemize}
\item mutacja
\item krzy¿owanie
\end{itemize}

Zadaniem mutacji jest losowe zmodyfikowanie genów w genotypie.\\
Krzy¿owanie, zwane tak¿e rekombinacj± (ang. \textit{crossover}), dzia³a na co najmniej dwóch osobnikach i na podstawie ich genotypów tworzy jeden lub wiêcej osobników potomnych. Chromosomy rodzicielskie s± mieszane w celu otrzymania nowych genotypów dla osobników potomnych.

W wyniku operacji genetycznych powstaj± nowe osobniki, które wchodz± w sk³ad populacji potomnej. Ka¿dy z tych osobników jest oceniany za pomoc± funkcji przystosowania. Porównuj±c jako¶æ osobników z populacji bazowej oraz potomnej dokonuje siê sukcesji, czyli wyboru osobników z tych populacji (czasem wy³±cznie z populacji potomnej) i tworzy now± populacjê bazow±.

Decyzja o zakoñczeniu dzia³ania algorytmu przewa¿nie podejmowana jest w oparciu o badanie warto¶ci funkcji przystosowania ca³ej populacji. Je¶li warto¶æ przystosowania populacji nie jest zró¿nicowana mówimy o stagnacji algorytmu i mo¿e byæ to wskazaniem do zakoñczenia dzia³ania algorytmu. Czasem jednak oczekuje siê a¿ przystosowanie to bêdzie wystarczaj±co du¿e, ¿eby stwierdziæ, ¿e znalezione rozwi±zanie jest bardzo dobre. Przewa¿nie jednak nie znamy nawet przybli¿onej warto¶ci przystosowania rozwi±zania, wiêc nie mo¿emy stwierdziæ kiedy przystosowanie jest odpowiednie i czy nie mo¿e siê jeszcze znacznie poprawiæ.

\subsubsection{Kodowanie osobników}
W przypadku algorytmów genetycznych do kodowania osobników stosuje siê kodowanie binarne chromosomów. Pojedynczy bit reprezentuje zatem gen nale¿±cy do chromosomu.\\
W takim przypadku mutacja wykonywana jest na ka¿dym genie osobno z pewnym prawdopodobieñstwem, je¶li do niej dochodzi, zmienia siê warto¶æ bitu na przeciwn±. W krzy¿owaniu wybiera siê dwa osobniki rodzicielskie, których chromosomy rozcinane s± na dwie czê¶ci i ³±czone ``na krzy¿''. Miejsce przeciêcia jest losowane z rozk³adem równomiernym.

W algorytmach ewolucyjnych porzuca siê kodowanie binarne - chromosom sk³ada siê z jednej lub wiêcej liczb stanowi±cych cechy osobnika.\\
Mutacja takiego osobnika najczê¶ciej odbywa siê poprzez losow± zmianê ka¿dej z warto¶ci genów chromosomu. Do krzy¿owania wybiera siê dwa osobniki, z których dla ka¿dej pary odpowiadaj±cych genów wyci±gana jest ¶rednia i tak otrzymane warto¶ci genów tworz± genotyp nowego osobnika.

\subsubsection{Typy algorytmów ewolucyjnych}
Algorytmy ewolucyjne wywodz± siê z kilku osobnych nurtów zajmuj±cych siê t± tematyk±, wiêc istnieje wiele podobnych schematów dzia³ania. Najlepiej traktowaæ algorytmy ewolucyjne jako metaheurystykê - okre¶lony jest pewien szkic algorytmu, który mo¿na dostosowywaæ do konkretnego rozwi±zania. W tym podrozdziale opisane s± podstawowe i najbardziej popularne schematy dzia³ania algorytmów ewolucyjnych.\\

\begin{enumerate}

\item{Prosty algorytm genetyczny}

Prosty algorytm genetyczny zosta³ zaproponowany w roku 1975 przez John'a Holland'a w \cite{Holland1975}.

Poni¿ej umieszczony jest schemat tego algorytmu (Algorytm \ref{alg:prostyGenetyczny} na podstawie algorytmu umieszczony w \cite{arabas}).

\begin{algorithm}
\caption{Prosty algorytm genetyczny}
\label{alg:prostyGenetyczny}
\begin{algorithmic}
\STATE	$t = 0$
\STATE	$P^0 = createInitPop() $
\WHILE {$stopCondition == false$}
\STATE	$T^t = createTempPop(P^t) $
\STATE	$T^t = crossPop(T^t) $
\STATE	$O^t = mutatePop(T^t) $
\STATE	$P^{t+1} = O^t$
\STATE	$t=t+1$
\ENDWHILE
\end{algorithmic}
\end{algorithm}


Maj±c populacjê bazow± $P^t$ dokonujemy reprodukcji tej populacji, tworz±c populacjê tymczasow± $T^t$ sk³adaj±c± siê z takiej samej liczby osobników. Wybierani s± oni z prawdopodobieñstwem proporcjonalnym do ich przystosowania z populacji bazowej. Na populacji tymczasowej dokonujemy operacji genetycznych (mutacji i krzy¿owania). Do krzy¿owania wybierane s± roz³±czne pary osobników i z pewnym prawdopodobieñstwem $p_c$ zachodzi ich skrzy¿owanie. Je¶li dosz³o do powstania osobników potomnych zastêpuj± one osobniki rodzicielskie. Nastêpnie na tak otrzymanej populacji tymczasowej dochodzi do mutacji osobników i otrzymania populacji potomnej $O^t$. Ta populacja staje siê w nastêpnej iteracji algorytmu now± populacj± bazow±.\\
Zatrzymanie algorytmu mo¿e byæ dokonane je¶li np.:

\begin{itemize}
\item wykonano okre¶lon± z góry liczbê iteracji
\item znaleziono osobnika o wystarczaj±co wysokiej warto¶ci przystosowania
\end{itemize}

W tej wersji algorytmu czêsto pêtlê algorytmu nazywa siê generacj±, a ka¿d± populacjê $P^t$ w chwili t pokoleniem.\\

\item{Strategia (1+1)}

Strategia (1+1) jest strategi± ewolucyjn± zaproponowan± przez Schwefel'a w 1965 r. \cite{Schwefelthesis}, a pó¼niej analizowana równie¿ w pracach Rechenberg'a \cite{rechenberg1971}, \cite{rechenberg1973}. W algorytmie tym mamy do czynienia z populacj± sk³adaj±c± siê tylko z jednego osobnika posiadaj±cego jeden chromosom. W ka¿dej pêtli algorytmu dokonuje siê mutacji tego chromosomu, co powoduje powstanie nowego osobnika. Osobnik ten jest poddawany ocenie, a nastêpnie dokonuje siê wyboru lepszego z dwóch istniej±cych osobników i tego pozostawia w populacji.\\
W mutacji dodaje siê do ka¿dego genu chromosomu losow± modyfikacjê rozk³adem normalnym:
\begin{equation}
Y^t_i = X^t_i + \sigma\xi_{N(0,1),i}
\end{equation}

Warto¶æ $\sigma$ bêdzie powodowa³a wiêksze lub mniejsze zmiany w chromosomie. Je¶li chcemy przeszukaæ przestrzeñ rozwi±zañ, powinni¶my zwiêkszaæ jej warto¶æ, co jest po¿±dane zw³aszcza w pocz±tkowej fazie dzia³ania algorytmu. Natomiast, aby znale¼æ jak najlepsze rozwi±zanie, wiedz±c ¿e obecne rozwi±zanie jest ju¿ bardzo bliskie najlepszemu, mo¿emy zmniejszaæ warto¶æ $\sigma$ przeszukuj±c tylko najbli¿sz± przestrzeñ.\\
Do wyznaczania $\sigma$ powsta³ nastêpuj±cy algorytm zwany regu³± 1/5 sukcesów (\cite{rechenberg1973}):
\begin{enumerate}
\item Je¶li przez kolejnych k pêtli algorytmu mutacja powoduje powstanie lepszego osobnika w wiêcej ni¿ 1/5 wszystkich mutacji, to zwiêkszamy $\sigma$: $\sigma' = c_i \sigma$. Warto¶æ $c_i$ wyznaczona empirycznie wynosi $ \frac{1}{0.82} $ (\cite{schwefel1981})
\item Gdy dok³adnie 1/5 koñczy siê sukcesem, warto¶æ $\sigma$ pozostaje bez zmian.
\item Je¶li nie zachodzi ¿adne z powy¿szych warto¶æ $\sigma$ jest zmniejszana: $\sigma' = c_d \sigma$. Gdzie $ c_d $ powinna wynosiæ $ 0.82 $ (\cite{schwefel1981})
\end{enumerate}

Opisane poni¿ej strategie s± rozwiniêciem strategii (1+1) i zosta³y zaproponowane przez Schwefel'a w \cite{Schwefel1975}, \cite{Schwefel1977}, \cite{schwefel1981}.

\item{Strategia ($\mu$ + $\lambda$)}

Strategia ($\mu$ + $\lambda$) jest rozwiniêciem strategii (1+1). $\mu$ oznacza ilo¶æ osobników w populacji pocz±tkowej, a $\lambda$ ile osobników jest reprodukowanych i poddawanych operacjom genetycznym. Dodatkowo, zamiast regu³y 1/5 sukcesów wprowadzono mechanizm samoczynnej adaptacji zasiêgu mutacji, a tak¿e wprowadzono operator krzy¿owania.

Oznaczenie $\mu$ + $\lambda$ oznacza, ¿e po wygenerowaniu populacji potomnej wybierane jest $\mu$ najlepszych osobników do nowej populacji bazowej - zarówno spo¶ród populacji potomnej, jak i starej populacji bazowej zawieraj±cych ³±cznie $\mu$ + $\lambda$ osobników. Algorytm \ref{alg:miPlusLambda} przedstawia schemat tej strategii (w oparciu o algorytm umieszczony w \cite{arabas}).

\begin{algorithm}
\caption{Strategia ewolucyjna ($\mu$ + $\lambda$)}
\label{alg:miPlusLambda}
\begin{algorithmic}
\STATE	$t = 0$
\STATE	$P^0 = createInitPop(\mu) $
\WHILE {$stopCondition == false$}
\STATE	$T^t = createTempPop(P^t,\lambda) $
\STATE	$T^t = crossPop(T^t) $
\STATE	$O^t = mutatePop(T^t) $
\STATE	$P^{t+1} = select(O^t \cup P^t,\mu)$
\STATE	$t=t+1$
\ENDWHILE
\end{algorithmic}
\end{algorithm}


W strategii tej wa¿ne jest te¿ kodowanie, do którego dodatkowo do³o¿ono chromosom przechowuj±cy wektor $\sigma$ zawieraj±cy warto¶ci odchyleñ standardowych, które wykorzystuje siê w trakcie mutacji.\\
Po wylosowaniu warto¶ci zmiennej losowej o rozk³adzie normalnym ($\xi_{N(0,1)}$) dla ka¿dego elementu wektora $\sigma$ losujemy jeszcze jedn± zmienn± losow± o rozk³adzie normalnym ($\xi_{N(0,1),i}$) i obliczamy nowe warto¶ci odchyleñ z wektora $\sigma$:

\begin{equation}
\sigma'_i = \sigma_i e^{(\tau'\xi_{N(0,1)} + \tau\xi_{N(0,1),i})}
\end{equation}


Gdzie $\tau$ oraz $\tau'$ s± parametrami algorytmu, a ich warto¶ci powinny wynosiæ wed³ug \cite{schwefel1995}:
\begin{equation}
\tau = \frac{K}{\sqrt{2n}}
\end{equation}

\begin{equation}
\tau' = \frac{K}{\sqrt{2\sqrt{n}}}
\end{equation}

gdzie:
\begin{itemize}
\item K - sta³a, najczê¶ciej stosuje siê warto¶æ 1 (\cite{schwefel1995})
\item n - wymiarowo¶æ zadania
\end{itemize}

Beyer w 2007 r. napisa³, ¿e empirycznie sprawdzono, ¿e nale¿y wybieraæ warto¶æ $\tau$ proporcjonalnie do $\frac{1}{\sqrt{n}}$. \cite{Beyer07}

Maj±c dane nowe warto¶ci odchyleñ standardowych mo¿emy obliczyæ nowe warto¶ci genów korzystaj±c ze wzoru:

\begin{equation}
X'_i = X_i + \sigma'_i\xi_{N(0,1),i}
\end{equation}
gdzie $\xi_{N(0,1),i}$ jest now± losow± warto¶ci±.

Algorytm ewolucyjny wybiera osobniki lepiej przystosowane, uwzglêdniaj±c przy tym równie¿ warto¶ci odchyleñ standardowych. Powoduje to naturaln± selekcjê, doprowadzaj±c± do samoczynnej adaptacji odchyleñ standardowych stosowanych w trakcie mutacji.

Krzy¿owanie wystêpuje w tym algorytmie pod nazw± ``rekombinacja''. Najczê¶ciej sprowadza siê do u¶rednienia lub wymianie warto¶ci sk³adowe wektorów, tak¿e warto¶ci $\sigma$.

\item{Strategia ($\mu$, $\lambda$)}

Strategia ($\mu$ + $\lambda$) posiada pewne wady, które wyeliminowano za pomoc± nowej strategii ($\mu$, $\lambda$). Poprzedni algorytm sprawia problemy je¶li w populacji pojawia siê osobnik o wysokiej warto¶ci przystosowania, ale posiadaj±cy zbyt du¿e (albo zbyt ma³e) warto¶ci odchyleñ standardowych. Usuniêcie takiego osobnika z populacji czêsto nie jest procesem krótkotrwa³ym, gdy¿ wp³ywa on na powstaj±ce potomstwo, przekazuj±c mu podobne do jego, nieodpowiednie warto¶ci odchyleñ.\\
W nowej strategii wprowadzono zmianê, która powoduje, ¿e osobniki rodzicielskie nie s± nigdy brane do kolejnej populacji bazowej. Podczas selekcji korzysta siê zatem tylko z powsta³ej populacji potomnej, z niej wybieraj±c osobniki do populacji bazowej w kolejnej iteracji. Algorytm \ref{alg:miLambda} prezentuje kolejne kroki schematu tego algorytmu (w oparciu o algorytm umieszczony w \cite{arabas}).

\begin{algorithm}
\caption{Strategia ewolucyjna ($\mu$, $\lambda$)}
\label{alg:miLambda}
\begin{algorithmic}
\STATE	$t = 0$
\STATE	$P^0 = createInitPop(\mu) $
\WHILE {$stopCondition == false$}
\STATE	$T^t = createTempPop(P^t,\lambda) $
\STATE	$T^t = crossPop(T^t) $
\STATE	$O^t = mutatePop(T^t) $
\STATE	$P^{t+1} = select(O^t,\mu)$
\STATE	$t=t+1$
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\end{enumerate}

\subsection{Algorytm memetyczny}
Richard Dawkins zaproponowa³ w \cite{dawkins89} pojêcie memu - ``the basic unit of cultural transmission, or imitation''. Algorytmy ewolucyjne opieraj± siê na ewolucji biologicznej, Dawkins zaproponowa³, ¿e istnieje równie¿ rozwój kulturowy. Na tej podstawie wprowadzono algorytmy memetyczne, które stanowi± rozwiniêcie algorytmów ewolucyjnych poprzez dodanie do nich lokalnej optymalizacji. Mo¿e byæ ona wprowadzana na ró¿nych etapach algorytmu (\cite{ChenOLT11}):

\begin{itemize}
\item na pocz±tku, w celu wygenerowanie potencjalnie lepszej populacji pocz±tkowej
\item w fazie oceny przystosowania
\item po mutacji i krzy¿owaniu
\item po zakoñczeniu fazy ewolucyjnej do ostatecznego poprawienia rozwi±zania
\end{itemize}

£±cz±c te dwa algorytmy ze sob±, mo¿emy wykorzystaæ i po³±czyæ ich zalety. Uwzglêdnienie algorytmu lokalnej optymalizacji pomaga w skutecznym znajdowaniu optimum lokalnego, jednak aby móc przeszukiwaæ wszystkie optima w celu znalezienia najlepszego - globalnego, potrzebujemy eksploracji jak± daje nam algorytm ewolucyjny.

\subsection{Hill Climbing}
\label{sec:hill}
Podrozdzia³ oparty jest o opis algorytmu Hill Climbing w \cite{russell}.

Algorytm Hill Climbing jest jedn± z metod przeszukiwania lokalnego. W podstawowej wersji algorytmu zwanej \textit{Greedy local search}, w ka¿dej iteracji zmieniaj±c warto¶æ rozwi±zania w jednym z wymiarów sprawdzana jest warto¶æ funkcji celu dla nowego rozwi±zania i je¶li warto¶æ ta jest lepsza od dotychczas najlepszej znalezionej, zapamiêtujemy zmienione rozwi±zanie. Dopóki zmiany powoduj± poprawê rozwi±zania, algorytm nie jest zatrzymywany. Na koñcu wiemy, ¿e znalezione rozwi±zanie jest rozwi±zaniem lokalnie optymalnym.

Istnieje wiele rodzajów algorytmu rozwijaj±cych wersjê podstawow±:

\begin{itemize}
\item \textit{Stochastic hill climbing} - wybiera kolejny punkt losowo, prawdopodobieñstwo wyboru mo¿e zale¿eæ od tego jak stromy jest krok,
\item \textit{First-choice hill climbing} - wybiera pierwszego z generowanych kolejno s±siadów, którego warto¶æ jest lepsza ni¿ obecny stan. Rozwi±zanie to warto stosowaæ je¶li istnieje wielu s±siadów,
\item \textit{Random-restart hill climbing} - uruchamiaj±c wielokrotnie algorytm rozpoczynaj±c w losowych punktach mo¿emy zwiêkszyæ prawdopodobieñstwo znalezienia rozwi±zania globalnego.
\end{itemize}

Przeszukiwanie przestrzeni dyskretnej sprowadza siê do sprawdzania rozwi±zañ najbli¿szych obecnemu i wybieranie tego rozwi±zania, którego warto¶æ obliczona za pomoc± funkcji celu jest najlepsza. Je¶li w¶ród s±siadów nie ma ju¿ lepszego rozwi±zania, mo¿emy zakoñczyæ przeszukiwanie. Pseudokod algorytmu przedstawiony jest poni¿ej (Algorytm \ref{alg:hillClimbDiscrete}).\\

\begin{algorithm}
\caption{Hill Climbing w przestrzeni dyskretnej}
\label{alg:hillClimbDiscrete}
\begin{algorithmic}
\STATE $current = startPoint$
\STATE $foundBetter = true $
\WHILE {$ foundBetter == true $}
  \STATE $ foundBetter = false $
  \STATE $ neighbours = getNeighbours(current) $
  \FORALL {$neighbour$ $in$ $neighbours$}
    \IF {$ neighbour.isBetterThan(current) $}
      \STATE $ current = neighbour $
      \STATE $ foundBetter = true $
    \ENDIF
  \ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}


W przestrzeni ci±g³ej konieczne jest dobranie kroku, który wyznacza punkty przeszukiwane w okolicy w trakcie ka¿dej iteracji. Dodatkowo wykorzystywane jest tzw. przyspieszenie (ang. \textit{acceleration}), które wyznacza piêciu mo¿liwych kandydatów na lepsze rozwi±zania. Najczê¶ciej przyspieszenie to wynosi 1.2, a warto¶æ kroku jest osobna dla ka¿dej zmiennej rozwi±zania i czêsto wynosi na pocz±tku 1. Zatem za ka¿dym razem obliczane s± nastêpuj±ce wspó³czynniki: -acceleration, -1/acceleration, 0, 1/acceleration, acceleration. Nastêpnie wspó³czynniki mno¿one s± przez krok (step) i dodawane do obecnie analizowanej zmiennej i wybierane jest najlepsze z piêciu rozwi±zañ. Warto¶æ kroku jest indywidualna dla ka¿dej zmiennej. Po wybraniu najlepszego rozwi±zania uaktualniana jest warto¶æ tego kroku - krok mno¿ony jest przez odpowiedni wspó³czynnik, ten który by³ dobrany wcze¶niej do znalezienia tego najlepszego rozwi±zania. Algorytm zatrzymywany jest je¶li zmiana ¿adnej ze zmiennych nie przynosi ju¿ poprawy rozwi±zania, czasem równie¿ je¶li ta zmiana jest ju¿ bardzo ma³a - wprowadzany jest parametr $\epsilon$ wyznaczaj±cy tê ró¿nicê. Pseudokod algorytmu przedstawiony jest na stronie \pageref{alg:hillClimbCont} (Algorytm \ref{alg:hillClimbCont}).


\begin{algorithm}
\caption{Hill Climbing w przestrzeni ci±g³ej}
\label{alg:hillClimbCont}
\begin{algorithmic}
\STATE $ currentResult = startPoint$
\STATE $ steps = initialSteps $ \COMMENT {for each dimension of the solution}
\STATE $ candidates = [-acc, -\frac{1}{acc}, 0, \frac{1}{acc}, acc] $
\STATE $ currentValue = currentResult.getValue() $
\STATE $ beforeValue = MAX\_VALUE $
\STATE $ \epsilon = EPSILON $
\WHILE {$ beforeValue - currentValue > \epsilon $}
  \STATE $ beforeValue = currentValue $
  \FOR {$i$ $in$ $dimensions$}
    \STATE $ bestIndex = -1 $
	\STATE $ bestScore = MAX\_VALUE $\
	\FOR {$j$ $in$ $candidatesNrs$} 
	  \STATE $ currentResult[i] = currentResult[i] + stepSize[i] * candidates[j] $
	  \STATE $ tempValue = currentResult.getValue() $
	  \STATE $ currentResult[i] = currentResult[i] - stepSize[i] * candidates[j] $
	  \IF {$tempValue.isBetterThan(bestScore)$}
	    \STATE $ bestScore = tempValue $
	    \STATE $ bestIndex = j $
	  \ENDIF
	\ENDFOR
	\IF {$ candidates[bestIndex]!=0 $}
   	  \STATE $ currentResult[i] = currentResult[i] + stepSize[i] * candidates[bestIndex] $
	  \STATE $ stepSize[i] = stepSize[i] * candidates[bestIndex] $    	  \COMMENT {accelerate}
	\ENDIF
  \ENDFOR
  \STATE $ currentValue = bestScore $
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\section{Inne podej¶cia do problemu znajdowania optymalnego toru przejazdu}
\label{sec:innePodejscia}

Matthew Brodie z Massey University w Nowej Zelandii jako pierwszy na ¶wiecie wykorzysta³ w³asnorêcznie zaprojektowany i wykonany system sk³adaj±cy siê z sieci miniaturowych czujników mocowanych na ciele zawodnika-narciarza, po³±czony z GPS, w celu ¶ledzenia i analizy ruchu narciarza jad±cego po slalomie. System, nazywaj±cy siê Motion Capture Fusion (FMC), zosta³ stworzony, by jak twierdzi autor, pomóc narciarzom ze ¶wiatowej czo³ówki lepiej rozumieæ, co dzieje siê z nimi podczas jazdy, zoptymalizowaæ jazdê, a w konsekwencji doprowadziæ ich do wiêkszej liczby zwyciêstw i z³otych medali. Opis systemu oraz wnioski zamie¶ci³ w swojej pracy doktorskiej pod tytu³em \textit{Optimisation of Performance in Alpine Ski Racing with Fusion Motion Capture} \cite{FMCNewZeland}. Prezentacjê systemu oraz jego funkcjonowania mo¿na obejrzeæ w kanale Matthew'a w serwisie YouTube.

\paragraph{Poni¿ej przedstawimy najwa¿niejsze wnioski Matthewa, zawarte w jego pracy doktorskiej}

\begin{itemize}
\item Optymalna strategia na pokonywanie trasy slalomu jest kompromisem miêdzy ciasnymi skrêtami, prowadz±cymi do toru o mniejszej d³ugo¶ci, a bardziej otwartymi skrêtami o wiêkszym promieniu, które umo¿liwiaj± utrzymanie wiêkszej prêdko¶ci w skrêcie.
\item Najkrótsza droga wcale nie jest czêsto najszybsz± drog±. Ka¿da bramka ma inny optymalny sposób na jej przejechanie.
\item Zawodnicy czêsto dobieraj± skrêty o identycznym promieniu skrêtu, bo jest to dla nich bardziej naturalne ni¿ skrêty o zmiennym promieniu. Tymczasem warto do ka¿dej bramki dobieraæ optymalny promieñ i punkt rozpoczêcia skrêtu.
\item W niektórych konfiguracjach terenu, optymalny promieñ skrêtu jest ograniczony poprzez maksymalny k±t pomiêdzy krawêdziami nart a ¶niegiem, jaki narciarz mo¿e utrzymaæ.
\item Wyniki do¶wiadczalne zaprzeczaj± wynikom laboratoryjnym i sugeruj±, ¿e podczas przejazdu slalomu giganta, opór ¶niegu ma tak samo du¿e znaczenia, co opór powietrza. 
\item W pewnych warunkach, tj. przy prêdko¶ci mniejszej ni¿ 20 m/s i terenie o nachyleniu mniejszym ni¿ 25 procent, narciarz mo¿e poprzez pracê miê¶ni - tzw. \textit{pompowanie} - zwiêkszyæ przyspieszenie w zakrêtach, a wiêc w rezultacie zmniejszyæ czas przejazdu. 
\item Dobór sprzêtu, dostosowanego zarówno do konkretnej trasy i jej nachylenia, jak i do warunków fizycznych zawodnika, ma znaczny wp³yw na otrzymywane przez niego wyniki.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[height=250px]{matt-1} 
\caption{Klatka z materia³u wideo na kanele Matthewa umieszczonego w serwisie YouTube, na którym pokazuje przygotowania do testowania systemu na stoku narciarskim. Na kasku narciarza widaæ zamontowany GPS}
\label{fig:matt-1} 
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[height=250px]{matt-2} 
\caption{Klatka z materia³u wideo na kanele Matthewa umieszczonego w serwisie YouTube, która przedstawia wizualizacjê zebranych na stoku danych w stworzonym przez Matthewa oprogramowaniu.}
\label{fig:matt-2} 
\end{figure}

%TODO @Ania to chyba nie jest miejsce w pracy na podsumowanie. Wspomne o tym w rozdzaile 6-tym ok? FIXME Marta podsumowanie czemu my lepsze ni¿ to albo przynajmniej inne 

\section{Wp³yw pozycji narciarza na szybko¶æ poruszania siê}
\label{sec:symulacjaPozycjaS}

W nawi±zaniu do sekcji teoretycznej \ref{sec:oporPowietrza} ze strony \pageref{sec:oporPowietrza}, w której jest zaznaczony wp³yw sylwetki narciarza na warto¶æ si³y oporu, warto pokazaæ aplikacjê stworzon± przez Francusk± Federacjê Narciarsk±.

Aplikacja jest skierowana do narciarzy z federacji i ma im pokazaæ jak bardzo wybór pozycji wp³ywa na ich ostateczny wynik na zawodach. U¿ytkownik ma do wyboru sze¶æ ró¿nych pozycji zjazdowych oraz trzy warto¶ci prêdko¶ci pocz±tkowych. Mo¿e wybraæ pozycjê bazow± oraz pozycjê docelow± oraz prêdko¶æ jak± ma bêd±c w pozycji bazowej. Program symuluje jaka bêdzie zmiana prêdko¶ci narciarza po przej¶ciu do pozycji docelowej po 100 metrach jazdy w dó³ w linii prostej. Co wiêcej, program wskazuje jaka bêdzie ró¿nica w prêdko¶ci narciarza po 200 metrach, z za³o¿eniem, ¿e po 100 metrach narciarz wróci³ do pozycji referencyjnej. Jest to o tyle istotne, ¿e pozwala u¶wiadomiæ zawodnikom, ¿e powinni wykorzystywaæ ka¿d± sytuacjê do przyjêcia jak najbardziej optymalnej pozycji. 

Zrzut ekranu aplikacji jest na rysunku \ref{fig:frenchapp} na stronie \pageref{fig:frenchapp}, a aplikacja opisana jest w pracy \cite{AirDrag}.
%TODE FIXME nie za bardzo dzia³a ten cite tutaj

\begin{figure}[H]
\centering
\includegraphics[height=270px]{frenchapp}
\caption{Zrzut ekranu z aplikacji Francuskiej Federacji Narciarskiej, zaczerpniêty z pracy AirDrag \cite{AirDrag}}
\label{fig:frenchapp}
\end{figure}

%---------------------------------------------------------------------------

