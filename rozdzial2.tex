\chapter{Wprowadzenie teoretyczne}
\label{cha:wstepTeoretyczny}

Zrozumienie istoty przedstawionego w tej pracy rozwi±zania doboru optymalnej trasy narciarza, zarówno pod wzglêdem algorytmicznym jak i architektonicznym, wymaga zaznajomienia siê z istotnymi pojêciami. W tym rozdziale, przedstawimy i opiszemy te pojêcia.

\section{Jazda po zadanym torze w narciarstwie alpejskim}
\label{sec:alpineSkiing}

Sportowa jazda na nartach zjazdowych podzielona jest na kilka dyscyplin. S± to: slalom (SL), slalom gigant (GS), super gigant (GS) oraz zjazd (DH). Elementem wspólnym ka¿dej z nich jest konieczno¶æ pokonania trasy, od startu do mety, w jak najkrótszym czasie i przy prawid³owym przejechaniu ka¿dej z bramek znajduj±cych siê na trasie przejazdu. Szczegó³owe zasady dotycz±ce parametrów stoku i sprzêtu okre¶la regulamin organizacji FIS (Federation International du Ski), z po¶ród których najbardziej istotnymi s±:

\begin{itemize}
\item minimalna i maksymalna ró¿nica wzniesieñ na trasie
\item minimalna i maksymalna odleg³o¶æ pomiêdzy kolejnymi bramkami
\item ilo¶æ bramek jaka powinna siê znale¼æ na trasie - proporcjonalnie do ró¿nicy wzniesieñ
\item wymagana d³ugo¶æ narty
\item wymagany promieñ skrêtu narty
\end{itemize}

Parametry te ró¿ni± siê w zale¿no¶ci od dyscypliny. Najbardziej techniczn± dyscyplin± jest slalom, nazywany wcze¶niej slalomem specjalnym. Techniczno¶æ tej dyscypliny polega na du¿ej ilo¶ci bramek znajduj±cych siê w niewielkiej odleg³o¶ci od siebie, co wymusza czêste skrêty. Zawodnicy je¿d¿± slalom na nartach o bardzo ma³ym promieniu skrêtu, rzêdu 11 metrów. Bramka w slalomie sk³ada siê z dwóch tyczek tego samego koloru. W slalomie gigancie, odleg³o¶ci miêdzy kolejnymi bramkami s± wiêksze, co implikuje szybsz± jazdê. Bramka w tej dyscyplinie sk³ada siê z czterech tyczek tego samego koloru, po dwie na ka¿dy koniec bramki. Dodatkowo ka¿de dwie tyczki z koñca bramki po³±czone s± p³acht± tego samego koloru co tyczki - czerwon± lub niebiesk±. Zawodnicy do tej dyscypliny u¿ywaj± nart o promieniu nawet 30 metrów. Kolejne dyscypliny s± jeszcze szybsze a promienie nart coraz wiêksze. Bramki zarówno w super gigancie jak i zje¼dzie, s± analogiczne do tych gigantowych, ró¿ni± siê tylko szeroko¶ci± p³acht. Super gigant, to bardziej \quotedblbase wypuszczony\textquotedblright slalom gigant, czyli slalom na którym odleg³o¶ci miêdzy bramkami s± ju¿ bardzo du¿e, a prêdko¶æ proporcjonalnie ro¶nie. Zjazd to ju¿ typowa dyscyplina szybko¶ciowa. Na trasie zakrêty wynikaj± prawie tylko z konfiguracji terenu. Dodatkowo zdarzaj± siê na trasie elementy ukszta³towania terenu na których zawodnicy wybijaj± siê i skacz± po nawet 20 metrów.

Aby poprawnie przejechaæ przez bramkê na trasie, w ka¿dej z opisywanych wy¿ej dyscyplin, nale¿y przejechaæ pomiêdzy tyczkami wyznaczaj±cymi tzw. \textit{¶wiat³o bramki}. Bramki wymuszaj± skrêty, ale nie jest tak, ¿e ustawione s± zawsze rytmicznie tzn. wymuszaj±c skrêty raz w praw±, raz w lew± stronê o tym samym promieniu. Najczê¶ciej spotykanym rodzajem bramki jest tzw. \textit{bramka otwarta}. Bramka otwarta, charakteryzuje siê tym, ¿e ¶wiat³o bramki znajduje siê prostopadle do linii spadku stoku. Poza bramkami otwartymi, bramki mog± byæ ustawione w tzw. figury slalomowe. Pierwsz± z nich jest \textit{przelot} i mo¿e wystêpowaæ w ka¿dej z dyscyplin. Przelot polega na ustawieniu dwóch kolejnych bramek w taki sposób, ¿e nie wymuszaj± skrêtu pomiêdzy nimi. Przelot stosowany jest w celu adaptacji trasy przejazdu do konfiguracji terenu, np. gdy na trasie naturalnie wystêpuje d³u¿szy skrêt w jedn± ze stron lub rozpêdzeniu narciarza. Kolejn± figur±, stosowan± ju¿ tylko w slalomie, jest \textit{³okieæ}. £okieæ to dwie bramki ustawione w bliskiej odleg³o¶ci jedna pod drug± w linii spadku stoku. S± to bramki zamkniête, czyli ¶wiat³o bramki jest zgodne z lini± spadku stoku. Figura ta wprowadza zmianê rytmu i równie¿ pozwala na dostosowanie trasy do konfiguracji terenu. Ostatni± z figur, równie¿ stosowan± tylko w slalomie, jest \textit{wertikal}. Wertikal to bramki ustawione tak samo jak w przypadku ³okcia, czyli jedna pod drug±, w linii spadku stoku, z tym, ¿e zamiast dwóch, mo¿e byæ trzy, cztery czy nawet piêæ kolejno tak ustawianych bramek.

%TODO FIXME Marta - napisz ¿e czasem warto zrobiæ wcze¶nie skrêt a czasem nie i o podkrêconych bramkach
Opisanie wy¿ej wymienionych elementów, by³o istotne by zrozumieæ problem znajdowania optymalnej trasy. Najtrudniejsze jest bowiem optymalne przejechanie figur slalomowych. Podczas ogl±dania trasy, przed zawodami czy te¿ podczas treningów, zawodnicy zwracaj± du¿± uwagê na zapamiêtanie wystêpuj±cych po sobie figur i przewidywanie, na podstawie do¶wiadczenia, w jaki sposób nale¿y najechaæ na dan± figurê, by zmie¶ciæ siê, czy te¿ najszybciej pokonaæ kolejne, nastêpuj±ce po danej figurze bramki. Poprzez najazd na figurê, rozumiemy moment rozpoczêcia i sposób prowadzenia skrêtu przed figur±. Im wcze¶niej narciarz zrobi najazd, tym szybciej, po poprawnym przejechaniu bramki, bêdzie móg³ zmieniæ kierunek jazdy do kolejnych tyczek.

%---------------------------------------------------------------------------

\section{Fizyczny model narciarza}
\label{sec:fizycznyModel}

%TODO FIXME jedno zdanie na temat rozdzia³u?

\subsubsection{Si³a oporu powietrza}
\label{sec:oporPowietrza}
Si³a oporu powietrza jest przyk³adem si³y tarcia p³ynu. Zale¿no¶æ warto¶ci tej si³y od prêdko¶ci mo¿e byæ bardzo z³o¿ona i skomplikowana i tylko w specjalnych przypadkach mo¿e byæ rozwi±zana analitycznie. Dla bardzo ma³ych warto¶ci prêdko¶ci, dla ma³ych cz±stek, si³a oporu powietrza jest wprost proporcjonalna do prêdko¶ci, a zale¿no¶æ ta mo¿e byæ opisana równaniem:

\begin{equation}
F_d = v b
\end{equation}

v - prêdko¶æ narciarza

Dla wiêkszych prêdko¶ci i wiêkszych obiektów, si³a oporu powietrza jest w dobrym przybli¿eniu proporcjonalna do kwadratu prêdko¶ci i zale¿no¶æ t±, mo¿na opisaæ równaniem:


\begin{equation}
F_d = \frac{1}{2}C\rho Av^2
\end{equation}

C - wspó³czynnik oporu powietrza, typowe warto¶ci oscyluj± miêdzy 0.4 a 1

$\rho$ - gêsto¶æ powietrza w jednostce $\frac{kg}{m^3}$. Warto¶ci gêsto¶ci powietrza przy przeciêtnym ci¶nieniu wahaj± siê miêdzy 1.26 a 1.42 w zale¿no¶ci od temperatury.

A - frontalna powierzchnia narciarza w projekcji prostopad³ej do wektora prêdko¶ci narciarza wyra¿ona w $m^{2}$.

\begin{figure}[h]
\label{fig:airDrag}
\centering
\includegraphics{airDrag}
\end{figure}

%TODO biblio link do badan
Na grafice \ref{fig:airDrag} na stronie \pageref{fig:airDrag} widzimy warto¶æ wspó³czynnika $A$ w zale¿no¶ci od pozycji narciarza. Grafika pochodzi z badañ prowadzonych w tunelu aerodynamicznym IAT we Francji, przez Caroline Barelle z National Technical University of Athens z Grecji.

Pozycja narciarza ma znacz±cy wp³yw na warto¶æ wspó³czynnika $A$. Przyjêcie pozycji zjazdowej redukuje w stosunku do pozycji podniesionej, warto¶æ wspó³czynnika nawet o jedn± trzeci±. Warto nadmieniæ równie¿, ¿e narciarze, nawet na amatorskich zawodach ubrani s± w specjalne kombinezony tzw. \textit{gumy narciarskie}. Kombinezony te s± jednoczê¶ciowe i ¶ci¶le przylegaj± do cia³a. Nie posiadaj± ¿adnych odstaj±cych elementów, czasami zawieraj± tylko wewnêtrzne ochraniacze w miejscach w których narciarz uderza przy ka¿dym skrêcie cia³em w tyczkê. Powodem dla którego strój ten jest tak popularny równie¿ w amatorskim sporcie jest fakt, ¿e znacz±co zmniejsza opór powietrza, w stosunku do klasycznego stroju narciarskiego i potrafi na kilkudziesiêciu sekundowej trasie, gdzie liczy siê ka¿da setna sekundy, redukowaæ czas przejazdu nawet o dziesiêtne czê¶ci sekundy.

\subsubsection{Interakcje miedzy ¶niegiem a nartami}
\label{sec:interakcje}
To, ¿e narty ¶lizgaj± siê na ¶niegu zawdziêczamy skomplikowanej fizyce interakcji miêdzy powierzchni± narty a ¶niegiem czy lodem. Ilo¶æ czynników jakie wp³ywaj± na jako¶æ tej interakcji jest bardzo du¿a, a z po¶ród nich warto wymieniæ:

\begin{itemize}
\item materia³ wykonania ¶lizgu narty
\item rodzaj, jako¶æ, sposób nak³adania i kolejno¶æ nak³adania smarów na ¶lizg narty
\item g³adko¶æ ¶lizgu narty
\item rodzaj i pochodzenie ¶niegu (naturalne/sztuczne)
\item temperatura i stopieñ zanieczyszczenia ¶niegu
\item k±t nachylenia miêdzy ¶lizgiem a pod³o¿em
\end{itemize}


Jest jeszcze jeden czynnik wp³ywaj±cy na tê interakcjê, tzw. \textit{water suction} (w wolnym t³umaczeniu zasysanie wody). W temperaturze powy¿ej -3 stopni Celsjusza, ciep³o powstaj±ce na skutek tarcia, topi cienk± warstwê ¶niegu pod nartami. Aby zredukowaæ ten negatywnie wp³ywaj±cy na po¶lizg efekt, ¶lizg narty ma perforowan± strukturê, któr± nale¿y zachowywaæ i odkrywaæ po ka¿dym smarowaniu, aby odprowadzaæ wodê. 


%TODO biblio Skiwaxes
Wed³ug badañ przeprowadzonych przez Chris'a Talbot'a z European Space Agency \cite{Skiwaxes}, tarcie o ¶nieg ma du¿o wiêkszy wp³yw na czas przejazdu ni¿ si³y tarcia powietrza.

\subsubsection{Tarcie kinetyczne}
\label{sec:tarcieKinetyczne}
Tarcie kinetyczne ma du¿o wiêksze znaczenie ni¿ tarcie statyczne poniewa¿ determinuje jak du¿a si³a musi dzia³aæ, ¿eby zachowaæ po¿±dan± prêdko¶æ podczas zjazdu. Wspó³czynnik tarcia kinetycznego miêdzy ¶niegiem a nasmarowanymi nartami wynosi ¶rednio 0.05. Wspó³czynnik ten jednak mo¿e siê znacz±co zmieniaæ i w zale¿no¶ci od rodzaju smarów, sposobu smarowania oraz jako¶ci ¶niegu wynosi miêdzy 0.001 a 0.3. Ró¿nica w warto¶ciach wspó³czynników ma prze³o¿enie w cenach smarów, które na warto¶ci tych wspó³czynników wp³ywaj±. Ju¿ na amatorskich zawodach, mo¿na zaobserwowaæ staranne przygotowanie ¶lizgów przed ka¿dym zjazdem i u¿ywanie smarów, których cena wynosi nawet kilkaset z³otych, a które s± zu¿ywane w ci±gu jednego sezonu startów.  


%---------------------------------------------------------------------------

%TODO FIXME Anka czy tu co¶ piszemy?
\section{Metody numeryczne rozwi±zywania równañ ró¿niczkowych}
\label{sec:numeryka}


%---------------------------------------------------------------------------

\section{Optymalizacja}
\label{sec:optymalizacja}

W tym podrozdziale opisane s± metody optymalizacji u¿yte w zaproponowanym rozwi±zaniu, czyli algorytm ewolucyjny oraz algorytm optymalizacji lokalnej - Hill climbing.

Zadaniem optymalizacji jest przeszukanie przestrzeni rozwi±zañ w celu znalezienia najlepszego. Zatem, dana jest funkcja, nazywan± funkcj± celu, która ka¿demu punktowi reprezentuj±cemu rozwi±zanie problemu przypisuje jak±¶ warto¶æ oceniaj±c± jego jako¶æ. W¶ród wszystkich rozwi±zañ poszukujemy takiego, dla którego warto¶æ tej funkcji bêdzie jak najmniejsza (b±d¼ jak najwiêksza) - najlepsza z naszego punktu widzenia. Trudno¶æ w znalezieniu takiego rozwi±zania zale¿y od charakteru funkcji celu, a czasem tak¿e od nieznajomo¶ci jej analitycznej postaci.

%TODO biblio Algorytmy genetyczne i cos?
\subsubsection{Optymalizacja lokalna i globalna}
W przypadku funkcji z jednym optimum do znalezienia najlepszego rozwi±zania wystarczy przeszukiwanie lokalne. Polega ono na iteracyjnym sprawdzaniu rozwi±zañ w najbli¿szej przestrzeni i wprowadzaniu lokalnych zmian, aby w koñcu znale¼æ rozwi±zanie najlepsze w okolicy tzw. optimum lokalne. Je¶li wiemy, ¿e istnieje tylko jedno takie optimum, mo¿emy mieæ pewno¶æ, ¿e znalezione rozwi±zanie jest najlepszym w ca³ej przestrzeni rozwi±zañ. Przyk³adami optymalizacji lokalnych s±:
\begin{itemize}
\item hill climbing
\item przeszukiwanie tabu
\end{itemize}

Je¶li natomiast funkcja celu posiada wiele optimów lokalnych (tzw. funkcja wielomodalna) to optymalizacjê nazywamy optymalizacj± globaln±. Je¶li zadanie jest ci±g³e, a wiêc niemo¿liwe jest przeszukanie ca³ej przestrzeni rozwi±zañ, nigdy nie mo¿emy byæ pewni, ¿e zastosowany algorytm optymalizacji da nam rozwi±zanie najlepsze - byæ mo¿e bêdzie to tylko minimum lokalne, a nie globalne. Nie maj±c takiej pewno¶ci nie wiemy kiedy nale¿y zatrzymaæ algorytm. Z tego powodu stosuje siê parametr steruj±cy czasem trwania obliczeñ - kosztem mniejszej pewno¶ci co do poprawno¶ci rozwi±zania mo¿emy otrzymaæ krótszy czas optymalizacji i odwrotnie.

\subsection{Algorytm ewolucyjny}
\label{sec:ewolucyjny}
Algorytm ewolucyjny jest przyk³adem algorytmu optymalizacyjnego, przeszukuj±cego przestrzeñ rozwi±zañ w celu znalezienia najlepszego rozwi±zania problemu. Algorytm ten oparty jest na obserwacjach ¶rodowiska i przystosowywania siê organizmów do jego warunków. Wiele terminów zapo¿yczonych jest zatem z genetyki.

Podstaw± ca³ego algorytmu jest populacja osobników, z których ka¿dy reprezentuje inne rozwi±zanie problemu. Populacja ta zmienia siê wraz z dzia³aniem algorytmu. Ewolucja zak³ada, ¿e populacja bêdzie siê sk³adaæ z coraz lepiej przystosowanych osobników. Przystosowanie to jest obliczane za pomoc± wcze¶niej okre¶lonej funkcji oceniaj±cej jako¶æ danego osobnika, czyli tak naprawdê wyznaczenie jak dobre jest rozwi±zanie reprezentowane przez niego. Przystosowanie jest warto¶ci± liczbow± obliczon± za pomoc± tej funkcji przystosowania.\\
Funkcja przystosowania okre¶la warto¶æ przystosowania osobnika na podstawie jego fenotypu, który jest tworzony z genotypu. Genotyp okre¶la zestaw cech danego osobnika i sk³ada siê z chromosomów (najczê¶ciej z jednego). Natomiast ka¿dy z chromosomów sk³ada siê z elementarnych jednostek - genów.\\

\subsubsection{Schemat dzia³a algorytmu ewolucyjnego}
Algorytm ewolucyjny rozpoczyna siê poprzez wygenerowanie populacji bazowej oraz obliczenie przystosowania jej osobników. Przewa¿nie osobniki te generowane s± ca³kowicie losowo, ale mo¿na tak¿e wprowadziæ konkretne osobniki np. o znanym dobrym przystosowaniu do ¶rodowiska.

G³ówna czê¶æ algorytmu opiera siê na powtarzaniu pêtli, w której wykonywane s± kolejno:

\begin{itemize}
\item reprodukcja
\item operacje genetyczne
\item ocena
\item sukcesja
\end{itemize}

Czêsto reprodukcjê i sukcesjê ³±czy siê pod nazw± selekcja.

Reprodukcja powoduje powielenie losowo wybranych osobników z populacji. Prawdopodobieñstwo wybrania osobnika do powielenia najczê¶ciej jest proporcjonalne do jego przystosowania. Mo¿e siê zdarzyæ, ¿e dany osobnik zostanie wybrany wiêcej ni¿ raz, a tak¿e, ¿e nie zostanie wybrany ani razu.\\
Nastêpnie na tych kopiach przeprowadzane s± operacje genetyczne powoduj±ce zmiany w genotypie osobników. Wyró¿niamy dwie podstawowe operacje:

\begin{itemize}
\item mutacja
\item krzy¿owanie
\end{itemize}

Zadaniem mutacji jest losowe zmodyfikowanie genów w genotypie.\\
Krzy¿owanie, zwane tak¿e rekombinacj± (ang. \textit{crossover}), dzia³a na co najmniej dwóch osobnikach i na podstawie ich genotypu tworzy jeden lub wiêcej osobników potomnych. Chromosomy rodzicielskie s± mieszane w celu otrzymania nowych genotypów dla osobników potomnych.

W wyniku operacji genetycznych powstaj± nowe osobniki, które wchodz± w sk³ad populacji potomnej. Ka¿dy z tych osobników jest oceniany za pomoc± funkcji przystosowania. Porównuj±c jako¶æ osobników z populacji bazowej oraz potomnej dokonuje siê sukcesji, czyli wyboru osobników z tych populacji (czasem wy³±cznie z populacji potomnej) i tworzy now± populacjê bazow±.

Zakoñczenie dzia³ania algorytmu przewa¿nie opiera siê na badaniu funkcji przystosowania ca³ej populacji. Je¶li warto¶æ przystosowania populacji nie jest zró¿nicowana mówimy o stagnacji algorytmu i mo¿e byæ to wskazaniem do zakoñczenia dzia³ania algorytmu. Czasem jednak oczekuje siê a¿ przystosowanie to bêdzie wystarczaj±co du¿e, ¿eby stwierdziæ, ¿e znalezione rozwi±zanie jest bardzo dobre. Przewa¿nie jednak nie znamy nawet przybli¿onej warto¶ci jako¶ci rozwi±zania, wiêc nie mo¿emy stwierdziæ kiedy przystosowanie jest odpowiednie i czy nie mo¿e siê jeszcze znacznie poprawiæ.

\subsubsection{Kodowanie osobników}
W przypadku algorytmów genetycznych, bêd±cych szczególnym przypadkiem algorytmów ewolucyjnych, do kodowania osobników stosuje siê kodowanie binarne chromosomów. Pojedynczy bit reprezentuje zatem gen nale¿±cy do chromosomu.\\
W takim przypadku mutacja wykonywana jest na ka¿dym genie osobno z pewnym prawdopodobieñstwem, je¶li do niej dochodzi, zmienia siê warto¶æ bitu na przeciwn±. W krzy¿owaniu wybiera siê dwa osobniki rodzicielskie, których chromosomy rozcinane s± na dwie czê¶ci i ³±czone "na krzy¿". Miejsce przeciêcia jest losowane z rozk³adem równomiernym.

W algorytmach ewolucyjnych porzuca siê kodowanie binarne - chromosom sk³ada siê z jednej lub wiêcej liczb stanowi±cych cechy osobnika.\\
Mutacja takiego osobnika najczê¶ciej odbywa siê poprzez losow± zmianê ka¿dej z warto¶ci genów chromosomu. Do krzy¿owania wybiera siê dwa osobniki, z których dla ka¿dej pary odpowiadaj±cych genów wyci±gana jest ¶rednia i tak otrzymane warto¶ci genów tworz± genotyp nowego osobnika.

\subsubsection{Typy algorytmów ewolucyjnych}
Algorytmy ewolucyjne wywodz± siê z kilku osobnych nurtów zajmuj±cych siê t± tematyk±, wiêc istnieje wiele podobnych schematów dzia³ania. Najlepiej traktowaæ algorytmy ewolucyjne jako metaheurystykê - okre¶lony jest pewien szkic algorytmu, który mo¿na dostosowywaæ do konkretnego rozwi±zania. W tym podrozdziale opisane s± podstawowe i najbardziej popularne schematy postêpowania oparte o algorytmy ewolucyjne.\\


\textbf{Prosty algorytm genetyczny}

Prosty algorytm genetyczny zosta³ zaproponowany w roku 1975 przez John'a Holland'a.

Poni¿ej umieszczony jest schemat tego algorytmu (Algorytm \ref{alg:prostyGenetyczny}).

\begin{algorithm}
\caption{Prosty algorytm genetyczny}
\label{alg:prostyGenetyczny}
\begin{algorithmic}
\STATE	$t = 0$
\STATE	$P^0 = createInitPop() $
\WHILE {$stopCondition == false$}
\STATE	$T^t = createTempPop(P^t) $
\STATE	$T^t = crossPop(T^t) $
\STATE	$O^t = mutatePop(T^t) $
\STATE	$P^{t+1} = O^t$
\STATE	$t=t+1$
\ENDWHILE
\end{algorithmic}
\end{algorithm}


Maj±c populacjê bazow± $P^t$ dokonujemy reprodukcji tej populacji, tworz±c populacjê tymczasow± $T^t$ sk³adaj±c± siê z takiej samej liczby osobników. Wybierani s± oni z prawdopodobieñstwem proporcjonalnym do ich przystosowania z populacji bazowej. Na populacji tymczasowej dokonujemy operacji genetycznych (mutacji i krzy¿owania). Do krzy¿owania wybierane s± roz³±czne pary osobników i z pewnym prawdopodobieñstwem $p_c$ zachodzi ich skrzy¿owanie. Je¶li dosz³o do powstania osobników potomnych zastêpuj± one osobniki rodzicielskie. Nastêpnie na tak otrzymanej populacji tymczasowej dochodzi do mutacji osobników i otrzymania populacji potomnej $O^t$. Ta populacja staje siê w nastêpnej iteracji algorytmu now± populacj± bazow±.\\
Zatrzymanie algorytmu mo¿e byæ dokonane je¶li np.:

\begin{itemize}
\item wykonano okre¶lon± z góry liczbê iteracji
\item znaleziono osobnika o wystarczaj±co wysokiej warto¶ci przystosowania
\end{itemize}

W tej wersji algorytmu czêsto pêtlê algorytmu nazywa siê generacj±, a ka¿d± populacjê $P^t$ w chwili t pokoleniem.\\

\textbf{Strategia (1+1)}

Strategia (1+1) jest podstawow± strategi± ewolucyjn±. W algorytmie tym mamy do czynienia z populacj± sk³adaj±c± siê tylko z jednego osobnika posiadaj±cego jeden chromosom. W ka¿dej pêtli algorytmu dokonuje siê mutacji tego chromosomu, co powoduje powstanie nowego osobnika. Osobnik ten jest poddawany ocenie, a nastêpnie dokonuje siê wyboru lepszego z dwóch istniej±cych osobników i tego pozostawia w populacji.\\
W mutacji dodaje siê do ka¿dego genu chromosomu losow± modyfikacjê rozk³adem normalnym:
\begin{equation}
Y^t_i = X^t_i + \sigma\xi_{N(0,1),i}
\end{equation}

Warto¶æ $\sigma$ bêdzie powodowa³a wiêksze lub mniejsze zmiany w chromosomie. Je¶li chcemy przeszukaæ przestrzeñ rozwi±zañ, powinni¶my zwiêkszaæ jej warto¶æ, co jest po¿±dane zw³aszcza w pocz±tkowej fazie dzia³ania algorytmu. Natomiast, aby znale¼æ jak najlepsze rozwi±zanie, wiedz±c ¿e obecne rozwi±zanie jest ju¿ bardzo bliskie najlepszemu, mo¿emy zmniejszaæ warto¶æ $\sigma$ przeszukuj±c tylko najbli¿sz± przestrzeñ.\\
Do wyznaczania $\sigma$ powsta³ nastêpuj±cy algorytm zwany regu³± 1/5 sukcesów:
\begin{enumerate}
\item Je¶li przez kolejnych k pêtli algorytmu mutacja powoduje powstanie lepszego osobnika w wiêcej ni¿ 1/5 wszystkich mutacji, to zwiêkszamy $\sigma$: $\sigma' = c_i \sigma$. Warto¶æ $c_i$ wyznaczona empirycznie wynosi $ \frac{1}{0.82} $
\item Gdy dok³adnie 1/5 koñczy siê sukcesem, warto¶æ $\sigma$ pozostaje bez zmian.
\item Je¶li nie zachodzi ¿adne z powy¿szych warto¶æ $\sigma$ jest zmniejszana: $\sigma' = c_d \sigma$. Gdzie $ c_d $ powinna wynosiæ $ 0.82 $
\end{enumerate}

\textbf{Strategia ($\mu$ + $\lambda$)}

Strategia ($\mu$ + $\lambda$) jest rozwiniêciem strategii (1+1). $\mu$ oznacza ilo¶æ osobników w populacji pocz±tkowej, a $\lambda$ ile osobników jest reprodukowanych i poddawanych operacjom genetycznym. Dodatkowo, zamiast regu³y 1/5 sukcesów wprowadzono mechanizm samoczynnej adaptacji zasiêgu mutacji, a tak¿e wprowadzono operator krzy¿owania.

Oznaczenie $\mu$ + $\lambda$ oznacza, ¿e po wygenerowaniu populacji potomnej wybierane jest $\mu$ najlepszych osobników do nowej populacji bazowej - zarówno spo¶ród populacji potomnej, jak i starej populacji bazowej zawieraj±cych ³±cznie $\mu$ + $\lambda$ osobników. Algorytm \ref{alg:miPlusLambda} przedstawia schemat dzia³ania.

\begin{algorithm}
\caption{Strategia ewolucyjna ($\mu$ + $\lambda$)}
\label{alg:miPlusLambda}
\begin{algorithmic}
\STATE	$t = 0$
\STATE	$P^0 = createInitPop(\mu) $
\WHILE {$stopCondition == false$}
\STATE	$T^t = createTempPop(P^t,\lambda) $
\STATE	$T^t = crossPop(T^t) $
\STATE	$O^t = mutatePop(T^t) $
\STATE	$P^{t+1} = select(O^t \cup P^t,\mu)$
\STATE	$t=t+1$
\ENDWHILE
\end{algorithmic}
\end{algorithm}


W strategii tej wa¿ne jest te¿ kodowanie, do którego dodatkowo do³o¿ono równie¿ chromosom przechowuj±cy wektor $\sigma$ zawieraj±cy warto¶ci odchyleñ standardowych, które wykorzystuje siê w trakcie mutacji.\\
Po wylosowaniu warto¶ci zmiennej losowej o rozk³adzie normalnym ($\xi_{N(0,1)}$) dla ka¿dego elementu wektora $\sigma$ losujemy jeszcze jedn± zmienn± losow± o rozk³adzie normalnym ($\xi_{N(0,1),i}$) i obliczamy nowe warto¶ci odchyleñ z wektora $\sigma$:

\begin{equation}
\sigma'_i = \sigma_i e^{(\tau'\xi_{N(0,1)} + \tau\xi_{N(0,1),i})}
\end{equation}


Gdzie $\tau$ oraz $\tau'$ s± parametrami algorytmu, a ich warto¶ci powinny wynosiæ:
\begin{equation}
\tau = \frac{K}{\sqrt{2n}}
\end{equation}

\begin{equation}
\tau' = \frac{K}{\sqrt{2\sqrt{n}}}
\end{equation}

%TODO biblio Schwefel(1995) (http://ls11-www.cs.uni-dortmund.de/people/rudolph/publications/papers/gra.pdf)
gdzie:
K - sta³a, najczê¶ciej stosuje siê warto¶æ 1
n - wymiarowo¶æ zadania

Maj±c dane nowe warto¶ci odchyleñ standardowych mo¿emy obliczyæ nowe warto¶ci genów korzystaj±c ze wzoru:

\begin{equation}
X'_i = X_i + \sigma'_i\xi_{N(0,1),i}
\end{equation}
gdzie $\xi_{N(0,1),i}$ jest now± losow± warto¶ci±.

Algorytm ewolucyjny wybiera osobniki lepiej przystosowane, a wiêc te, które posiadaj± tak¿e lepsze warto¶ci odchyleñ standardowych. Powoduje to naturaln± selekcjê, doprowadzaj±c± do samoczynnej adaptacji odchyleñ standardowych stosowanych w trakcie mutacji.

Krzy¿owanie wystêpuje w tym algorytmie pod nazw± rekombinacja. Najczê¶ciej sprowadza siê do u¶rednienia lub wymianie warto¶ci wektorów, tak¿e wektora $\sigma$.

\textbf{Strategia ($\mu$, $\lambda$)}
Strategia ($\mu$ + $\lambda$) posiada pewne wady, które postanowiono spróbowaæ wyeliminowaæ za pomoc± nowej strategii ($\mu$, $\lambda$). Poprzedni algorytm sprawia problemy je¶li w populacji pojawia siê osobnik o wysokiej warto¶ci przystosowania, ale posiadaj±cy zbyt du¿e (albo zbyt ma³e) warto¶ci odchyleñ standardowych. Usuniêcie takiego osobnika z populacji czêsto nie jest procesem krótkotrwa³ym, gdy¿ wp³ywa on na powstaj±ce potomstwo, przekazuj±c mu podobne do jego, nieodpowiednie warto¶ci odchyleñ.\\
W nowej strategii wprowadzono zmianê, która powoduje, ¿e osobniki rodzicielskie nie s± nigdy brane do kolejnej populacji bazowej. Podczas selekcji korzysta siê zatem tylko z powsta³ej populacji potomnej, z niej wybieraj±c osobniki do populacji bazowej w kolejnej iteracji. Algorytm \ref{alg:miLambda} prezentuje kolejne kroki schematu tego algorytmu.

\begin{algorithm}
\caption{Strategia ewolucyjna ($\mu$, $\lambda$)}
\label{alg:miLambda}
\begin{algorithmic}
\STATE	$t = 0$
\STATE	$P^0 = createInitPop(\mu) $
\WHILE {$stopCondition == false$}
\STATE	$T^t = createTempPop(P^t,\lambda) $
\STATE	$T^t = crossPop(T^t) $
\STATE	$O^t = mutatePop(T^t) $
\STATE	$P^{t+1} = select(O^t,\mu)$
\STATE	$t=t+1$
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\subsection{Hill Climbing}
\label{sec:hill}
%TODO biblio ksiazka Stuart Russell, Peter Norvig - Artificial Inteligence A Modern Approach

Algorytm Hill Climbing jest jedn± z metod przeszukiwania lokalnego. W ka¿dej iteracji zmieniaj±c warto¶æ rozwi±zania w jednym z wymiarów sprawdzana jest warto¶æ funkcji celu dla nowego rozwi±zania i je¶li warto¶æ ta jest lepsza od dotychczas najlepszej znalezionej, zapamiêtujemy zmienione rozwi±zanie. Dopóki zmiany powoduj± poprawê rozwi±zania, algorytm nie jest zatrzymywany. Na koñcu wiemy, ¿e znalezione rozwi±zanie jest rozwi±zaniem lokalnie optymalnym.\\
Przeszukiwanie przestrzeni dyskretnej sprowadza siê do sprawdzania rozwi±zañ najbli¿szych obecnemu i wybieranie tego rozwi±zania, którego warto¶æ obliczona za pomoc± funkcji celu jest najlepsza. Je¶li w¶ród s±siadów nie ma ju¿ lepszego rozwi±zania, mo¿emy zakoñczyæ przeszukiwanie. Pseudokod algorytmu przedstawiony jest poni¿ej (Algorytm \ref{alg:hillClimbDiscrete}).\\

\begin{algorithm}
\caption{Hill Climbing w przestrzeni dyskretnej}
\label{alg:hillClimbDiscrete}
\begin{algorithmic}
\STATE $current = startPoint$
\STATE $foundBetter = true $
\WHILE {$ foundBetter == true $}
  \STATE $ foundBetter = false $
  \STATE $ neighbours = getNeighbours(current) $
  \FORALL {$neighbour$ $in$ $neighbours$}
    \IF {$ neighbour.isBetterThan(current) $}
      \STATE $ current = neighbour $
      \STATE $ foundBetter = true $
    \ENDIF
  \ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}


W przestrzeni ci±g³ej konieczne jest dobranie kroku, który wyznacza punkty przeszukiwane w okolicy w trakcie ka¿dej iteracji. Dodatkowo wykorzystywane jest tzw. przyspieszenie (ang. \textit{acceleration}), które wyznacza piêciu mo¿liwych kandydatów na lepsze rozwi±zania. Najczê¶ciej przyspieszenie to wynosi 1.2, a warto¶æ kroku jest osobna dla ka¿dej zmiennej rozwi±zania i czêsto wynosi na pocz±tku 1. Zatem za ka¿dym razem obliczane s± nastêpuj±ce wspó³czynniki: -acceleration, -1/acceleration, 0, 1/acceleration, acceleration. Nastêpnie wspó³czynniki mno¿one s± przez krok (step) i dodawane do obecnie analizowanej zmiennej i wybierane jest najlepsze z piêciu rozwi±zañ. Warto¶æ kroku jest indywidualna dla ka¿dej zmiennej. Po wybraniu najlepszego rozwi±zania uaktualniana jest warto¶æ tego kroku - krok mno¿ony jest przez odpowiedni wspó³czynnik, ten który by³ dobrany wcze¶niej do znalezienia tego najlepszego rozwi±zania. Algorytm zatrzymywany jest je¶li zmiana ¿adnej ze zmiennych nie przynosi ju¿ poprawy rozwi±zania, czasem równie¿ je¶li ta zmiana jest ju¿ bardzo ma³a - wprowadzany jest parametr $\epsilon$ wyznaczaj±cy tê ró¿nicê. Pseudokod algorytmu przedstawiony jest na stronie \pageref{alg:hillClimbCont} (Algorytm \ref{alg:hillClimbCont}).


\begin{algorithm}
\caption{Hill Climbing w przestrzeni ci±g³ej}
\label{alg:hillClimbCont}
\begin{algorithmic}
\STATE $ currentResult = startPoint$
\STATE $ steps = initialSteps $ \COMMENT {for each dimension of the solution}
\STATE $ candidates = [-acc, -\frac{1}{acc}, 0, \frac{1}{acc}, acc] $
\STATE $ currentValue = currentResult.getValue() $
\STATE $ beforeValue = MAX\_VALUE $
\STATE $ \epsilon = EPSILON $
\WHILE {$ beforeValue - currentValue > \epsilon $}
  \STATE $ beforeValue = currentValue $
  \FOR {$i$ $in$ $dimensions$}
    \STATE $ bestIndex = -1 $
	\STATE $ bestScore = MAX\_VALUE $\
	\FOR {$j$ $in$ $candidatesNrs$} 
	  \STATE $ currentResult[i] = currentResult[i] + stepSize[i] * candidates[j] $
	  \STATE $ tempValue = currentResult.getValue() $
	  \STATE $ currentResult[i] = currentResult[i] - stepSize[i] * candidates[j] $
	  \IF {$tempValue.isBetterThan(bestScore)$}
	    \STATE $ bestScore = tempValue $
	    \STATE $ bestIndex = j $
	  \ENDIF
	\ENDFOR
	\IF {$ candidates[bestIndex]!=0 $}
   	  \STATE $ currentResult[i] = currentResult[i] + stepSize[i] * candidates[bestIndex] $
	  \STATE $ stepSize[i] = stepSize[i] * candidates[bestIndex] $    	  \COMMENT {accelerate}
	\ENDIF
  \ENDFOR
  \STATE $ currentValue = bestScore $
\ENDWHILE
\end{algorithmic}
\end{algorithm}

%---------------------------------------------------------------------------

%TODO biblio
\section{Volunteer Computing}
\label{volunteerComputing}

Volunteer Computing to nieformalny kontrakt, w którym zwykli ludzie czy te¿ organizacje, nazywani dalej ochotnikami, dobrowolnie udostêpniaj± swoje zasoby obliczeniowe, by uruchamiaæ na nich obliczenia zwi±zane z ró¿norakimi projektami. S± to przewa¿nie projekty naukowe, których celem jest rozwi±zanie problemów i zadañ matematycznych czy te¿ problemów dotykaj±cych ludzko¶æ, lub d±¿±cych do lepszego poznania ¶wiata i wszech¶wiata. Dziêki platformom umo¿liwiaj±cym Volunteer Computing, ka¿dy cz³owiek mo¿e w niewielkim stopniu mieæ wk³ad w rozwi±zywanie tych problemów.

Procesory w komputerach osobistych spêdzaj± oko³o 80 procent czasu nie robi±c nic. Równocze¶nie wiele naukowych problemów zwi±zanych na przyk³ad z modelowaniem zmian klimatu potrzebuje ogromnych zasobów obliczeniowych. U¿ywanie do tego celu superkomputerów jest bardzo drogie. Po³±czenie tych faktów doprowadzi³o do stworzenia konceptu, by u¿ywaæ do tych obliczeñ zasobów zwyk³ych ludzi, którzy chc± siê ¶wiadomie nimi dzieliæ. Obecne do¶wiadczenia wskazuj±, ¿e wydajno¶æ systemu dla pojedynczo prowadzonego projektu opartego o Volunteer Computing jest porównywalna do tego, gdyby projekt prowadzony by³ przy wsparciu jednego z topowych superkomputerów z listy TOP500.

Ochotnicy to osoby prywatne albo instytucje takie jak szko³y czy uniwersytety. Ochotnicy przewa¿nie pozostaj± anonimowi, choæ w niektórych projektach wymagane jest dostarczenie podstawowych danych kontaktowych jak np. adresu email. W wypadku celowego dostarczania b³êdnych wyników przez ochotnika, utrudnione jest jego dyscyplinowanie czy te¿ wy³±czenie z projektu. Ochotnicy nie s± wynagradzani finansowo za uczestnictwo w projekcie. 

Organizacja czy osoba chc±ca wykorzystaæ model Volunteer computing do swoich projektów, musi byæ jednostk± zaufan± dla ochotników realizuj±cych obliczenia. Wynika to z prostego faktu, ¿e ochotnicy decyduj± siê, wed³ug standardowego modelu computing, na zainstalowanie aplikacji dostarczanej przez dawcê zadañ obliczeniowych. Osoba instaluj±ca aplikacjê musi ufaæ, ¿e nie uszkodzi ona jej komputera, ani te¿ nie bêdzie wykorzystywaæ jej zasobów w sposób niezgodny z zapewnieniami zleceniodawcy obliczeñ. Zleceniobiorca obliczeñ ma te¿ prawo oczekiwaæ, ¿e aplikacja, zosta³a napisana przestrzegaj±c dobrych praktyk bezpieczeñstwa, gdy¿ jako, ¿e aplikacja ta ³±czy siê z internetem i potencjalnie jest zainstalowana na du¿ej ilo¶ci maszyn, jest wiêc atrakcyjnym celem ataków zmierzaj±cych do przejêcia tych maszyn do niezgodnych z prawem celów przez hakerów. 

Przewa¿nie model komunikacyjny systemu Volunteer Computing uwzglêdnia tylko komunikacjê poszczególnych klientów z centralnym serwerem i nie zak³ada bezpo¶redniej komunikacji miêdzy klientami.

Volunteer Computing pierwotnie zak³ada³, ¿e obliczenia s± wykonywane na zwyk³ych komputerach osobistych (PC). Ilo¶æ komputerów tego typu jest nieporównywalnie wiêksza ni¿ ilo¶æ wyspecjalizowanych komputerów o du¿ej mocy obliczeniowej i jest szacowana na ponad miliard. Dodatkowo, z przyczyn ekonomicznych, na rozwój tych maszyn producenci sprzêtu przeznaczaj± najwiêksze fundusze, wiêc ich moc i zdolno¶ci obliczeniowe stale rosn±. 

Wa¿nym aspektem, który istotnie wp³ywa na stosowanie modelu w praktyce, jest koszt prowadzenia obliczeñ. Model zak³ada, ¿e do³±czanie siê do obliczeñ jest dobrowolne i nie dostaje siê za uczestnictwo w projekcie wynagrodzenia. Dziêki temu, projekty, które maj± poparcie i akceptacjê spo³eczn± mog± liczyæ na darmowe moce obliczeniowe udostêpnione przez zwyk³ych ludzi.

Na ten model mo¿na patrzyæ tak¿e w kategoriach edukacyjnych. Podczas gdy ochotnik przystêpuje do projektu i udostêpnia swoje moce obliczeniowe, mo¿na wykorzystaæ jego potencjalne zainteresowanie rozwi±zywanym problemem i za pomoc± przystêpnych wizualizacji przedstawiæ mu sedno rozwi±zywanego zadania, nakre¶liæ mu problem z ró¿nych perspektyw i pokazaæ mu do czego potencjalnie zmierzaj± obliczenia. Po³±czenie atrakcyjnej formy t³umaczenia rozwi±zywanych problemów z potencja³em portali spo³eczno¶ciowych i popularno¶ci ciekawego materia³u mo¿na uzyskaæ daleko id±cy efekt propagacji i pod³±czaniu siê do obliczeñ coraz wiêkszej ilo¶ci osób.

%TODO biblio
\section{Web Workers}
\label{webWorkers}

Przeprowadzanie intensywnych obliczeñ w przegl±darkach internetowych nie by³o mo¿liwe do czasu wprowadzenia przez grupê WHATWG (Web Hypertext Application Technology Working Group) specyfikacji Web Worker. Ograniczenie wynika³o z faktu, ¿e jêzyk w którym wykonywane s± skrypty poprzez silniki przegl±darki to Java Script. Java Script to ¶rodowisko jednow±tkowe, wiêc nic nie mo¿e byæ wykonywane równolegle. Zlecaj±c wiêc skryptowi intensywne obliczenia, na ich ca³y czas UI strony by³by nieresponsywny, co jest nie do przyjêcia dla cz³owieka obs³uguj±cego stronê internetow±. Przegl±darki broni± u¿ytkownika przed takim zachowaniem skryptów na stronie i czasami zdarza siê jeszcze zobaczyæ okno z ostrze¿eniem, ¿e skrypt przesta³ odpowiadaæ i mo¿liwo¶ci± manualnego zatrzymania skryptu.

Web Workers definiuje API do tworzenia osobnych procesów w tle. Worker'y wykorzystuj± do komunikacji z w±tkiem g³ównym klasyczny model przekazywania wiadomo¶ci. Nowoczesne przegl±darki umo¿liwiaj± przekazywanie zarówno tekstu jak i obiektów zserializowanych w formacie JSON. Nale¿y zwróciæ uwagê, ¿e obiekty te nie s± wspó³dzielone, ale w pe³ni kopiowane. 

Web Worker'y nie maj± dostêpu do struktury DOM, obiektu \textit{window} ani \textit{document}. Zewnêtrzne skrypty wykorzystywane przez worker'a musz± byæ serwowane z tej samej domeny co kod worker'a.

Wed³ug specyfikacji, stworzonej przez WHATWG, Web Workery powinny byæ u¿ywane do zadañ trwaj±cych d³u¿szy czas, maj±cych du¿y narzut startowy i spory narzut pamiêciowy. Nie jest wiêc odpowiednim tworzenie bardzo wielu worker'ów zajmuj±cych siê obliczeniami trwaj±cymi marginalny czas, gdy¿ sam narzut na stworzenie przez przegl±darkê osobnego procesu mo¿e byæ zbyt du¿y, by uzasadniæ jego u¿ycie.
